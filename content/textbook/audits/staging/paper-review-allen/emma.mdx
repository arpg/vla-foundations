First pass: fill Sections 1, 3, 9

Second pass: fill Sections 2, 4

Final pass: fill Sections 6, 8, 10

# Paper Audit Notes

**Paper title:**  EMMA
**Authors / Year:**  
**Group theme:**  
**Link / PDF:**  

---

## 1. Core Claim & Motivation
Full end-to-end (sensors -> trajectory) autonomous driving with multimodal large language model. 

- Problem statement: I feel like this isn't super motivated. I guess the consensus is the algorithms could always be better and there is always something to improve. 

- Why existing methods fail: They fail to accurately capture the information that leads to successfully driving actions and input it into the model.

- Main contribution: Two gigantic internally developed dataset, three task definitions. Spatial reasoning (find all objects -> turn into text input). Road Graph Estimation (road graph (nodes representing lanes and lane curvature -> turn into text input, big improvement here using dynamically allocated points for lanes instead of fixed point number). Scene understanding (is the road ahead temporarily blocked? -> text "yes", "no" human generated labels. didnt improve model.))

- Claimed novelty: Model shows that training across multiple tasks at once improves the performance then training for one task in particular. Therefore, maybe defining more tasks or the right tasks and co-training could produce better models.

> One-sentence summary in plain language:

---

## 2. Technical Approach
*(How the method actually works)*

### Architecture / Model
- Backbone(s): Gemini 1.0 Nano-1
- Modalities: Vision and Text
- Fusion mechanism: Two headed attention
- Action / policy output format: Local Frame Ego Future Trajectories. Bonus capabilities (spatial reasoning, road comprehension, scene understanding, which all pipe into an additional Chain of Thought reasoning pipeline)

### Training Setup
- Driving Dataset(s): nuScenes (18,686 examples), Waymo Motion Dataset (487,061), Internal (24,374,046)
- Detection Dataset(s): Waymo Detection (158,081), Internal (11,765,140)
- Roadgraph Dataset(s): Internal (8,304,671)
- Supervision type: Self-Supervised (future paths are known from the logged driving data)
- Loss functions: TODO
- Pretraining vs finetuning: TODO 
- Key hyperparameters: TODO

> Important equations / definitions:
> - 
> - 

---

## 3. Assumptions/Limitations
*(What must be true for this to work)*

### Perception
360 camera vision (fails due to occlusions, lighting conditions, obstructions, lens flare)
- 

### Data
- limited number of frames 4 (bad at long-term reasoning)
- lack of depth 

### Control & Dynamics
- predicted driving signals appear to be consistent but can't be gauaranteed

### Embodiment
- Cant be run realtime, propose model with 3FPS inference compare against worst model
for speed up percentage, provide no metrics on accuracy.

> What breaks first on a real robot?

---

## 4. Evaluation & Evidence
*(How the authors justify their claims)*

### Benchmarks / Tasks
- Simulation or real-world:
- Tasks:
- Metrics:
- Baselines:

### Results
- Clear wins:
- Weak or failing cases:
- Any suspicious comparisons: 

> Figures / tables worth citing:
> - Fig. __:
> - Table __:

Uses nuScene as validation which is sensitive to hyperparameter tuning , scenarios lack diversity and are often solved by estrapolating historical trajectories (which is being used in training)
---

## 5. Scaling Properties
*(Does this method scale? At what cost?)*
Totally scalable given driving datasets with ground truth trajectories

- Model size(s):
- Dataset size(s):
- Compute requirements:
- Evidence of scaling laws:

> Is scaling smooth, brittle, or untested?

---

## 6. Information Flow & Decay
*(Where information is lost across the pipeline)*

- Perception â†’ Representation:
- Representation â†’ Planning:
- Planning â†’ Control:
- Language â†’ Action grounding:

> Where does precision degrade the most?

---

## 7. Limitations

### Stated by Authors
- 

### My Critique
- Unrealistic assumptions:
- Missing ablations:
- Failure modes not discussed:

---

## 8. Comparison Hooks
*(Notes to use when comparing across papers)*

- Compared to other papers:
  - More / less general?
  - More / less scalable?
  - More / less physically grounded?

---

## 9. Key Takeaway
*(1â€“2 sentences you could put directly in the audit)*

> 

---

## 10. Questions for the Audit
*(What you would challenge or ask the authors)*

- 
- 
- 

---

## ðŸš© Red Flags (check if applicable)
- [ ] Sim-only validation
- [ ] No real-time constraints discussed
- [ ] Unclear action representation
- [ ] Language not grounded in control
- [ ] Results rely on massive hidden data
- [ ] Evaluation tasks too narrow

---
