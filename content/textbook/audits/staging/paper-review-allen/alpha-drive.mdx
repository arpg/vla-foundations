First pass: fill Sections 1, 3, 9

Second pass: fill Sections 2, 4

Final pass: fill Sections 6, 8, 10

# Paper Audit Notes

**Paper title:**  
**Authors / Year:**  
**Group theme:**  
**Link / PDF:**  

---

## 1. Core Claim & Motivation
*(What problem is being solved and why this paper exists)*

- Problem statement:
- Why existing methods fail:
- Main contribution:
- Claimed novelty:

> One-sentence summary in plain language:

---

## 2. Technical Approach
*(How the method actually works)*

### Architecture / Model
- Backbone(s):
- Modalities:
- Fusion mechanism:
- Action / policy output format:

### Training Setup
- Dataset(s):
- Supervision type:
- Loss functions:
- Pretraining vs finetuning:
- Key hyperparameters:

> Important equations / definitions:
> - 
> - 

---

## 3. Assumptions
*(What must be true for this to work)*

### Perception
- 

### Data
- 

### Control & Dynamics
- 

### Embodiment
- 

> What breaks first on a real robot?

---

## 4. Evaluation & Evidence
*(How the authors justify their claims)*

### Benchmarks / Tasks
- Simulation or real-world:
- Tasks:
- Metrics:
- Baselines:

### Results
- Clear wins:
- Weak or failing cases:
- Any suspicious comparisons:

> Figures / tables worth citing:
> - Fig. __:
> - Table __:

---

## 5. Scaling Properties
*(Does this method scale? At what cost?)*

- Model size(s):
- Dataset size(s):
- Compute requirements:
- Evidence of scaling laws:

> Is scaling smooth, brittle, or untested?

---

## 6. Information Flow & Decay
*(Where information is lost across the pipeline)*

- Perception â†’ Representation:
- Representation â†’ Planning:
- Planning â†’ Control:
- Language â†’ Action grounding:

> Where does precision degrade the most?

---

## 7. Limitations

### Stated by Authors
- 

### My Critique
- Unrealistic assumptions:
- Missing ablations:
- Failure modes not discussed:

---

## 8. Comparison Hooks
*(Notes to use when comparing across papers)*

- Compared to other papers:
  - More / less general?
  - More / less scalable?
  - More / less physically grounded?

---

## 9. Key Takeaway
*(1â€“2 sentences you could put directly in the audit)*

> 

---

## 10. Questions for the Audit
*(What you would challenge or ask the authors)*

- 
- 
- 

---

## ðŸš© Red Flags (check if applicable)
- [ ] Sim-only validation
- [ ] No real-time constraints discussed
- [ ] Unclear action representation
- [ ] Language not grounded in control
- [ ] Results rely on massive hidden data
- [ ] Evaluation tasks too narrow

---
