---
title: 'The VLA Capstone: Engineering the Frontier'
assignment: 3
due: 'Finals Week'
points: 250
---

# The VLA Capstone: From Audit to Architecture

**Weight:** 25% of Final Grade
**Initial Project Specification Due:** Leading into the Architecture Lab (This Thursday).
**Mastery Deadline:** Finals Week.

## The Philosophy: Audit, Implement, Extend

In this course, we do not perform "re-implementations" for the sake of practice. The Capstone is a substantive contribution to the `vlm-robotics.dev` living textbook. You are expected to move from an auditor (Assignment 2) to an architect—identifying a bottleneck, proposing a delta, and proving it via implementation.

## Project Tracks

Choose **one** of the following tracks for your technical deep-dive:

### Track 1: Research Extension (The "Delta" Track)
Extend an existing VLA paper with novel experiments. 
- **Requirement:** Reproduce a baseline, then design experiments testing a specific "Initial Dissolve" (e.g., "Does RT-2 generalize to novel object geometries created in simulation?").
- **Textbook Contribution:** A section analyzing your findings and the "Information Decay" observed.

### Track 2: Engineering Implementation (The "Systems" Track)
Build a production-grade VLA component from scratch.
- **Requirement:** Implement a key technique (e.g., an optimized vision encoder for 50Hz control, a cross-embodiment training harness).
- **Textbook Contribution:** A technical "Implementation Gotchas" guide and practitioners' manual for your component.

### Track 3: Synthesis & Taxonomy (The "Survey" Track)
Write an authoritative survey of a VLA sub-domain.
- **Requirement:** Read 15-20 papers. Identify the "Lineage of Failure" and the scaling laws of the sub-topic.
- **Textbook Contribution:** A foundational chapter synthesizing the literature into a cohesive taxonomy.

---

## Technical Requirements

### 1. The Architectural Delta
Your project must identify a specific bottleneck in a "Primary Paper." You are not parrots; you are auditors. If you choose Track 1 or 2, you must justify your architectural changes using the **Amazon Principle**: write a technical specification that proves why this change is necessary.

### 2. The Data Mix
You must explicitly define your data curation strategy:
- **Foundational Priors:** Which internet-scale weights (SigLIP, DINOv2) are you using?
- **Embodied Data:** Which subset of Open X-Embodiment or DROID are you sampling?
- **Synthetic Multiplication:** Are you using *MimicGen* or *RoboGen* to scale your seeds?

### 3. Formalized Logic & Derivations
Your documentation must be grounded in $\LaTeX$. 
- Derive your specific loss function $\mathcal{L}_{total}$.
- Define the state-space $S$ and the action-space $A$ (e.g., Delta-EE, Joint Velocities, or Latent Tokens).

### 4. Semantic Form
All MDX contributions must follow the **Semantic Line Break** rule (one sentence per line). This is mandatory for the PR review process.

---

## Team Structure: The $2\times$ Rule

- **Individual Work:** The baseline for a high-quality contribution.
- **Group Work (Optional):** If you choose to work in a group, the technical bar for "Mastery" scales linearly. A 2-person team must go **$2\times$ as far**—meaning significantly larger data mixes, more robust baseline comparisons, or cross-embodiment evaluation. 
- **Note:** Groups must provide a "Team Contribution Statement" in their proposal.

---

## Deliverables & Grading Rubric (250 Points Total)

### 1. Project Specification / Proposal (Pass/Fail - First Architectural Lab)
Submit via the **VLA Architecture Lab Form**. Includes team members, the "Initial Dissolve," and compute/data requirements.

### 2. Textbook Chapter Contribution (100 Points)
- **Technical Accuracy & Rigor (50 pts):** Correct $\LaTeX$, sound mathematical derivations, and deep critique.
- **Writing & Insights (50 pts):** Must include *Lineage of Failure*, *Intuitive Derivations*, and *Implementation Gotchas*.

### 3. Code Implementation (75 Points)
- **Functionality & Correctness (50 pts):** Does it solve the stated bottleneck?
- **Code Quality & Docs (25 pts):** Clean Python, README with setup, and unit tests. 

### 4. Final Presentation (75 Points)
- **Content Density (50 pts):** 15-minute technical brief.
- **Q&A Rigor (25 pts):** Ability to defend your load-bearing assertions.

---

## Submission Process: The PR Workflow

1. **Branching:** `git checkout -b project/your-handle-topic`
2. **Pathing:** - **Textbook:** `content/textbook/[chapter]/your-section.mdx`
   - **Code:** `code/capstone/your-project/`
   - **Slides:** `presentations/your-name-final.pdf`
3. **The Loop:** Open a PR to `staging`. A bot will provide a preview link. Iterate until your project reaches **Level 3 (Mastery)** and is merged into the `main` textbook.

> **Final Note:** The capstone is your opportunity to make a lasting contribution to the VLA research community. Aim for work you would be proud to showcase in an AI Engineering interview.

---

## Spring 2026 Projects

### Group A — Multi-Modal Sensing Lab

- **Whole-body proximity sensing for VLAs** — [![](https://github.com/jdvakil.png?size=20)](https://github.com/jdvakil) [Jay Vakil](https://github.com/jdvakil)
- **Latent proximal space / contact dreaming** *(pair)* — [![](https://github.com/cKohl10.png?size=20)](https://github.com/cKohl10) [Carson Kohlbrenner](https://github.com/cKohl10) · [![](https://github.com/jdvakil.png?size=20)](https://github.com/jdvakil) [Jay Vakil](https://github.com/jdvakil)
- **Radar-VLA for degraded sensing environments** — [![](https://github.com/kalhamilton.png?size=20)](https://github.com/kalhamilton) [Kali Hamilton](https://github.com/kalhamilton)
- **Cross-modal latent alignment** — [![](https://github.com/antony-zhao.png?size=20)](https://github.com/antony-zhao) [Antony Zhao](https://github.com/antony-zhao)
- **Gaze-conditioned VLA for intent alignment** — [![](https://github.com/gyanigk.png?size=20)](https://github.com/gyanigk) [Gyanig](https://github.com/gyanigk)

### Group B — Action & Policy Benchmark

- **Cross-task generalization in small-scale VLAs** — [![](https://github.com/Tr0612.png?size=20)](https://github.com/Tr0612) [Thanushraam](https://github.com/Tr0612)
- **Diffusion vs. autoregression vs. RL: apples-to-apples comparison** — [![](https://github.com/Soorej30.png?size=20)](https://github.com/Soorej30) [Soorej S Nair](https://github.com/Soorej30)
- **Adversarial strategic reasoning in VLAs** — [![](https://github.com/krusnim.png?size=20)](https://github.com/krusnim) [Mel Krusniak](https://github.com/krusnim)
- **Risk-aware RL in VLA training** — [![](https://github.com/lorinachey.png?size=20)](https://github.com/lorinachey) [Lorin Achey](https://github.com/lorinachey)

### Group C — Grounding & Interaction Lab

- **Kinematic-aware grasp selection via VLM** — [![](https://github.com/Hhy903.png?size=20)](https://github.com/Hhy903) [Heyang Huang](https://github.com/Hhy903)
- **Active preference learning via VLM** — [![](https://github.com/yi-shiuan-tung.png?size=20)](https://github.com/yi-shiuan-tung) [Yi-Shiuan Tung](https://github.com/yi-shiuan-tung)
- **Click-to-action VLA for real robots** — [![](https://github.com/yuni-wyx.png?size=20)](https://github.com/yuni-wyx) [Yuni Wu](https://github.com/yuni-wyx)

### Group D — Planning & Safety Lab

- **Uncertainty as a near-failure signal** — [![](https://github.com/aritrach.png?size=20)](https://github.com/aritrach) [Aritra Chakrabarty](https://github.com/aritrach)
- **Safety-aware VLA for high-latency sensing** — [![](https://github.com/jt7347.png?size=20)](https://github.com/jt7347) [Jimmy Tran](https://github.com/jt7347)
- **Belief-aware VLA via particle filter** — [![](https://github.com/himanshugupta1009.png?size=20)](https://github.com/himanshugupta1009) [Himanshu Gupta](https://github.com/himanshugupta1009)
- **Long-horizon planning via VOI-POMDP** — [![](https://github.com/zlaouar.png?size=20)](https://github.com/zlaouar) [Zakariya Laouar](https://github.com/zlaouar)
