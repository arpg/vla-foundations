<!DOCTYPE html><!--LLF8f_EKq47XF6vgKHpAS--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/staging/pulls/62/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/staging/pulls/62/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="https://github.com/Tr0612.png?size=64" as="image"/><link rel="stylesheet" href="/staging/pulls/62/_next/static/chunks/71a910c5d8fbeaac.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/staging/pulls/62/_next/static/chunks/ae74cfb856e78d53.js"/><script src="/staging/pulls/62/_next/static/chunks/840d34cdd84cd2d9.js" async=""></script><script src="/staging/pulls/62/_next/static/chunks/39ad0e90583997ed.js" async=""></script><script src="/staging/pulls/62/_next/static/chunks/cb6932692d241ade.js" async=""></script><script src="/staging/pulls/62/_next/static/chunks/turbopack-4ddbe55b844040bc.js" async=""></script><script src="/staging/pulls/62/_next/static/chunks/3421e88d40c9134c.js" async=""></script><script src="/staging/pulls/62/_next/static/chunks/fbf372f7eb8336a2.js" async=""></script><script src="/staging/pulls/62/_next/static/chunks/9bba833e6f3a8653.js" async=""></script><meta name="next-size-adjust" content=""/><title>Thanushraam (Tr0612): Cross-Task Generalization in Small VLAs — Capstone Running Log - VLA Capstone</title><meta name="description" content="Capstone project report for @Tr0612"/><link rel="icon" href="/staging/pulls/62/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><script src="/staging/pulls/62/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen bg-white"><div class="max-w-4xl mx-auto px-6 py-16"><a class="text-sm text-blue-600 hover:text-blue-800 mb-8 inline-block" href="/staging/pulls/62/course/assignments/capstone/">← Back to Capstone</a><div class="mb-8"><div class="flex items-center gap-3 mb-4"><span class="text-sm font-medium text-blue-600 bg-blue-50 px-3 py-1 rounded-full border border-blue-200">Group B</span><span class="text-sm font-medium text-slate-600 bg-slate-100 px-3 py-1 rounded-full">Action &amp; Policy Benchmark</span><span class="text-sm font-medium text-amber-600 bg-amber-50 px-3 py-1 rounded-full border border-amber-200">Finals Week</span></div><div class="flex items-center gap-3"><img src="https://github.com/Tr0612.png?size=64" alt="Tr0612" width="48" height="48" class="rounded-full"/><div><h1 class="text-3xl font-bold text-gray-900">Thanushraam (Tr0612): Cross-Task Generalization in Small VLAs — Capstone Running Log</h1><a href="https://github.com/Tr0612" class="text-sm text-slate-500 hover:text-slate-700" target="_blank" rel="noopener noreferrer">@<!-- -->Tr0612</a></div></div></div><div class="prose prose-lg max-w-none"><h1>Thanushraam: Cross-Task Generalization in Small VLAs — Capstone Running Log</h1>
<p><strong>GitHub:</strong> <a href="https://github.com/Tr0612">@Tr0612</a>
<strong>Group:</strong> B — Action &amp; Policy Benchmark</p>
<hr/>
<h2>Part I — Project Proposal</h2>
<h3>The Problem</h3>
<p>Testing cross-task generalization in small-scale VLA models.
Current small VLA models (TinyVLA, SmolVLA, OpenVLA) are evaluated on training-distribution tasks; their ability to transfer to novel but related manipulation tasks is underexplored.</p>
<h3>Base Model</h3>
<p>TinyVLA, SmolVLA, and OpenVLA as reference architectures.
A custom VLA stack built from scratch referencing these papers.</p>
<h3>The Delta</h3>
<p>A new policy head in which the model learns multiple expert action modules that specialize in different manipulation behaviors, similar to a Mixture-of-Experts (MoE) approach.
The model is trained on a subset of MetaWorld tasks and evaluated on related but unseen tasks to study cross-task generalization and the effectiveness of modular action specialization.
Additional simulated datasets added to improve diversity and robustness.
If resources permit: sim-to-real transfer as an extension.</p>
<h3>Data Mix Strategy</h3>
<p>Approximately 60% internet priors through pre-trained vision-language representations.
Approximately 30% embodied data from Open X-Embodiment (OXE) and MetaWorld for policy learning.
Approximately 10% synthetic data generated in simulation to cover rare or edge-case manipulation scenarios.</p>
<h3>Compute Requirements</h3>
<p>20 hours on RTX 4070 or RTX 5080.
Aiming to run inference on CPU.</p>
<h3>Success Metric</h3>
<p>Task success rate in simulation (primary metric).
Cross-task generalization gap: performance on training tasks vs. held-out tasks.
Robustness to language variation: different prompt styles (simple, detailed, task-specific).
If resources permit: limited real-robot trials on a simple manipulation task for sim-to-real transfer.</p>
<h3>Evaluation Scale</h3>
<p>2–3 held-out MetaWorld tasks, each tested with multiple prompt styles.
20–50 closed-loop rollouts per task (approximately 100–150 total evaluation episodes).
Additional synthetic evaluation set with domain randomization (lighting shifts, camera noise, distractors): approximately 50–100 perturbed episodes.
If sim-to-real: small set of real-robot demonstrations collected manually.</p>
<hr/>
<h2>Part II — Architecture Lab 1 Peer Audit</h2>
<p><em>Source: PR <a href="https://github.com/arpg/vla-foundations/pull/52">#52</a> (krusnim). Scribed by Mel; presented by Lorin. No generative tools used to produce this document.</em></p>
<h3>Lorin: Utilizing Risk Profiles in VLAs</h3>
<p><strong>Goal:</strong> Change action outputs based on a risk profile.
This profile should be encoded in an RL policy so the stack is risk-aware.
Example: get X close to a person without entering a &quot;risk zone.&quot;</p>
<p><strong>Data:</strong> An &quot;OpenVLA or Octo type dataset,&quot; possibly Open X-Embodiment (OXE).
A small collection of simulation data on a robot arm is required for fine-tuning, collected via IsaacSim/IsaacLab.</p>
<p><strong>Training:</strong> Scaling is a major concern.
Training an RL policy and then evaluating will take a while.
It is not necessarily compute-heavy to collect a small dataset and demonstrate one safe and one unsafe trajectory that are meaningfully different.</p>
<p><strong>Discussion:</strong>
Thanush asked about dataset details.
Ideally a mix of internet-scale and fine-tuning data; an exact mix has not been determined yet.
If computational issues arise, scaling down to minimum is necessary.
The minimum dataset would be a supervised fine-tuning set created from teleoperation in simulation.
The project starts with a very simple task: designating a risk zone and a safe zone.</p>
<p>Soorej asked how the safe/unsafe zone will be validated.
There is a binary classification component, but quantifying how far inside the safe zone the robot is would also be valuable.
A full understanding of the distribution of actions and their rewards/costs is the goal.</p>
<p>Mel asked about the base VLA.
Probably OpenVLA, Octo, or SmolVLA — whichever provides easier setup and future scalability (open weights, full robot models).</p>
<p>Mel asked whether there is a particular safe RL work this draws from.
Statistical analysis tools on the RL training stage are applicable: risk-aware PPO implementations, value iteration/Bellman adjustments.
A simpler value iteration could be the starting point; distributional RL with PPO is also a strong candidate.</p>
<p>Thanush asked whether a sensor on the arm would help produce data/safety measurements.
Additional sensors with fixed, rule-based emergency stop policies are valid but redundant.
There are reasons to not rely solely on rule-based vision or proximity sensors.
When deploying in real life, if the on-arm camera fails, the system still needs to determine what is safe.</p>
<h3>Thanush: MoE Policy Head for MetaWorld Generalization</h3>
<p><strong>Goal:</strong> Based on TinyVLA, build a VLA stack with a new policy head to learn multiple expert action modules for different manipulation behaviors.
Train on a fragment of MetaWorld tasks; evaluate on related but unseen tasks to determine generalization capabilities.</p>
<p><strong>Data:</strong> Sourced from MetaWorld.
<strong>Training:</strong> On a consumer GPU.</p>
<p><strong>Discussion:</strong>
Soorej asked how &quot;difficulty&quot; of tasks is defined.
Training on easy tasks and testing on difficult ones, and vice versa, should both be evaluated.
MetaWorld has ten tasks total; if a model trained to open a drawer cannot open a fridge, that is a generalization failure.</p>
<p>Lorin asked about the compute setup.
TinyVLA has parameters on the order of millions; a consumer GPU should suffice.</p>
<p>Lorin asked whether the plan is to pick an existing architecture like TinyVLA.
The goal is to build something from scratch and train on a dataset.
A comparison will then be made after adding the new custom policy head.</p>
<h3>Soorej: Apples-to-Apples Policy Comparison</h3>
<p><strong>Goal:</strong> Compare a diffusion policy, an autoregressive approach, and an RL approach to visuomotor control with identical datasets and architectures — essentially an ablation.</p>
<p><strong>Data:</strong> Unknown; likely Open X-Embodiment.
<strong>Training:</strong> 5–10 GPU hours for each model.</p>
<p><strong>Discussion:</strong>
Lorin asked about the RL method.
PPO or GRPO.</p>
<p>Lorin asked whether flow matching was considered.
Not yet, but it is an interesting possibility.</p>
<p>Mel asked about compute requirements and backbone considerations.
5–10 GPU hours per model.
The diffusion backbone will be based on the vision model control paper.
For autoregression, it will be a plain Transformer.</p>
<p>Thanush asked whether training setups will differ across methods.
Ideally no.</p>
<p>Lorin asked what dataset will be used.
Open X-Embodiment, maybe.</p>
<p>Lorin asked about major concerns and plan B.
Moving to smaller models or a smaller dataset and comparing only RL and autoregression is the fallback.</p>
<p>Lorin asked how outputs in the action space will be compared.
Currently unsure.</p>
<h3>Mel: Adversarial Strategic Reasoning in VLAs</h3>
<p><em>(Scribed by Soorej)</em></p>
<p><strong>Goal:</strong> In adversarial multiagent settings, the correct, least-exploitable action outputs are stochastic — but the stochasticity output by a VLA may not match the correct action weights.
The goal is to generate analytically correct trajectories and fine-tune the VLA so that token probabilities align with strategically optimal mixed-action trajectories.</p>
<p><strong>Root model:</strong> MiniVLA (or TinyVLA, VQ-BeT).
<strong>Data:</strong> Partially world model data, partially single-agent robot data, partially generated adversarial data.</p>
<p><strong>Discussion:</strong>
Lorin asked whether training is required.
Yes — fine-tuning with the adversarial data.
The opponent in all cases will be a fixed policy (not a second VLA) to simplify training.
The goal is to avoid being exploited by that fixed opponent.</p>
<p>Lorin asked about expected computational cost.
GPUs are available.
OpenVLA can apparently be fine-tuned in about a dozen hours; the narrower robot data may reduce the number of training hours needed.</p>
<p>Lorin asked for the simplest possible demonstration.
A common example is tag; getting more complicated or general than that would be ideal.
Tag is good because it is very easy to analytically generate mixed probabilistic trajectories.</p>
<p>Lorin noted this project seems more complex than the others and asked about a simpler backup plan.
One option: focus only on action tokenization — a potential modification of VQ-BeT where the latent action space focuses on encoding the most strategically relevant actions first.</p>
<h3>Overarching Commentary</h3>
<p><strong>Load-bearing walls:</strong>
Data is the primary load-bearing wall.
For Lorin and Mel, data generation will be required and difficult to get right.
Thanush and Soorej will use exclusively existing data — potentially easier but still a bottleneck.
Simulation is the shared substrate; none of these projects will be deployed on hardware.
Information decay: all projects simplify more complex problems, losing action information in the process.
This is a particularly sharp problem for Soorej, where action spaces will differ across methods.</p>
<p><strong>Unresolved engineering question:</strong>
The group struggled to identify a single unifying engineering question, given the diversity of projects.
Generating data in simulation is the central problem for action-centric projects (Lorin and Mel).
Defining standards for apples-to-apples comparisons is the focus for benchmarking-centric projects (Thanush and Soorej).
Sharing a general data pipeline for internet-scale and robot data across projects is a potential efficiency gain.</p>
<p><strong>Most robust initial dissolve:</strong>
No single most-robust initial dissolve was named.</p>
<hr/>
<h2>Part III — Instructor Feedback</h2>
<blockquote>
<p><strong>@crheckman</strong> — <em>To be completed during finals week.</em></p>
</blockquote>
<h3>Score</h3>
<table><thead><tr><th>Student</th><th>GitHub</th><th>Proposal</th><th>Chapter</th><th>Code</th><th>Presentation</th><th>Total</th></tr></thead><tbody><tr><td>Thanushraam</td><td>@Tr0612</td><td>—</td><td>—</td><td>—</td><td>—</td><td>—</td></tr></tbody></table>
<h3>Commentary</h3>
<p><em>Placeholder for instructor notes.</em></p></div><div class="mt-12 pt-8 border-t border-gray-200"><a class="text-blue-600 hover:text-blue-800 font-medium" href="/staging/pulls/62/course/assignments/capstone/">← Back to Capstone</a></div></div></div><!--$--><!--/$--><script src="/staging/pulls/62/_next/static/chunks/ae74cfb856e78d53.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[69460,[\"/staging/pulls/62/_next/static/chunks/3421e88d40c9134c.js\",\"/staging/pulls/62/_next/static/chunks/fbf372f7eb8336a2.js\"],\"default\"]\n3:I[24820,[\"/staging/pulls/62/_next/static/chunks/3421e88d40c9134c.js\",\"/staging/pulls/62/_next/static/chunks/fbf372f7eb8336a2.js\"],\"default\"]\n5:I[39795,[\"/staging/pulls/62/_next/static/chunks/3421e88d40c9134c.js\",\"/staging/pulls/62/_next/static/chunks/fbf372f7eb8336a2.js\"],\"OutletBoundary\"]\n6:\"$Sreact.suspense\"\n8:I[39795,[\"/staging/pulls/62/_next/static/chunks/3421e88d40c9134c.js\",\"/staging/pulls/62/_next/static/chunks/fbf372f7eb8336a2.js\"],\"ViewportBoundary\"]\na:I[39795,[\"/staging/pulls/62/_next/static/chunks/3421e88d40c9134c.js\",\"/staging/pulls/62/_next/static/chunks/fbf372f7eb8336a2.js\"],\"MetadataBoundary\"]\nc:I[8528,[],\"default\"]\n:HL[\"/staging/pulls/62/_next/static/chunks/71a910c5d8fbeaac.css\",\"style\"]\n:HL[\"/staging/pulls/62/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/staging/pulls/62/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"LLF8f_EKq47XF6vgKHpAS\",\"c\":[\"\",\"course\",\"assignments\",\"capstone\",\"Tr0612\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"course\",{\"children\":[\"assignments\",{\"children\":[\"capstone\",{\"children\":[[\"handle\",\"Tr0612\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/staging/pulls/62/_next/static/chunks/71a910c5d8fbeaac.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",[[\"$\",\"script\",\"script-0\",{\"src\":\"/staging/pulls/62/_next/static/chunks/9bba833e6f3a8653.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L5\",null,{\"children\":[\"$\",\"$6\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@7\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$La\",null,{\"children\":[\"$\",\"$6\",null,{\"name\":\"Next.Metadata\",\"children\":\"$Lb\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$c\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"d:I[32888,[\"/staging/pulls/62/_next/static/chunks/9bba833e6f3a8653.js\"],\"\"]\n:HL[\"https://github.com/Tr0612.png?size=64\",\"image\"]\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-white\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-6 py-16\",\"children\":[[\"$\",\"$Ld\",null,{\"href\":\"/course/assignments/capstone\",\"className\":\"text-sm text-blue-600 hover:text-blue-800 mb-8 inline-block\",\"children\":\"← Back to Capstone\"}],[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-3 mb-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-sm font-medium text-blue-600 bg-blue-50 px-3 py-1 rounded-full border border-blue-200\",\"children\":\"Group B\"}],[\"$\",\"span\",null,{\"className\":\"text-sm font-medium text-slate-600 bg-slate-100 px-3 py-1 rounded-full\",\"children\":\"Action \u0026 Policy Benchmark\"}],[\"$\",\"span\",null,{\"className\":\"text-sm font-medium text-amber-600 bg-amber-50 px-3 py-1 rounded-full border border-amber-200\",\"children\":\"Finals Week\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-3\",\"children\":[[\"$\",\"img\",null,{\"src\":\"https://github.com/Tr0612.png?size=64\",\"alt\":\"Tr0612\",\"width\":48,\"height\":48,\"className\":\"rounded-full\"}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-3xl font-bold text-gray-900\",\"children\":\"Thanushraam (Tr0612): Cross-Task Generalization in Small VLAs — Capstone Running Log\"}],[\"$\",\"a\",null,{\"href\":\"https://github.com/Tr0612\",\"className\":\"text-sm text-slate-500 hover:text-slate-700\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[\"@\",\"Tr0612\"]}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"prose prose-lg max-w-none\",\"children\":\"$Le\"}],[\"$\",\"div\",null,{\"className\":\"mt-12 pt-8 border-t border-gray-200\",\"children\":[\"$\",\"$Ld\",null,{\"href\":\"/course/assignments/capstone\",\"className\":\"text-blue-600 hover:text-blue-800 font-medium\",\"children\":\"← Back to Capstone\"}]}]]}]}]\n"])</script><script>self.__next_f.push([1,"e:[[\"$\",\"h1\",null,{\"children\":\"Thanushraam: Cross-Task Generalization in Small VLAs — Capstone Running Log\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"GitHub:\"}],\" \",[\"$\",\"a\",null,{\"href\":\"https://github.com/Tr0612\",\"children\":\"@Tr0612\"}],\"\\n\",[\"$\",\"strong\",null,{\"children\":\"Group:\"}],\" B — Action \u0026 Policy Benchmark\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Part I — Project Proposal\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"The Problem\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Testing cross-task generalization in small-scale VLA models.\\nCurrent small VLA models (TinyVLA, SmolVLA, OpenVLA) are evaluated on training-distribution tasks; their ability to transfer to novel but related manipulation tasks is underexplored.\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"Base Model\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"TinyVLA, SmolVLA, and OpenVLA as reference architectures.\\nA custom VLA stack built from scratch referencing these papers.\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"The Delta\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"A new policy head in which the model learns multiple expert action modules that specialize in different manipulation behaviors, similar to a Mixture-of-Experts (MoE) approach.\\nThe model is trained on a subset of MetaWorld tasks and evaluated on related but unseen tasks to study cross-task generalization and the effectiveness of modular action specialization.\\nAdditional simulated datasets added to improve diversity and robustness.\\nIf resources permit: sim-to-real transfer as an extension.\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"Data Mix Strategy\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Approximately 60% internet priors through pre-trained vision-language representations.\\nApproximately 30% embodied data from Open X-Embodiment (OXE) and MetaWorld for policy learning.\\nApproximately 10% synthetic data generated in simulation to cover rare or edge-case manipulation scenarios.\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"Compute Requirements\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"20 hours on RTX 4070 or RTX 5080.\\nAiming to run inference on CPU.\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"Success Metric\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Task success rate in simulation (primary metric).\\nCross-task generalization gap: performance on training tasks vs. held-out tasks.\\nRobustness to language variation: different prompt styles (simple, detailed, task-specific).\\nIf resources permit: limited real-robot trials on a simple manipulation task for sim-to-real transfer.\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"Evaluation Scale\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"2–3 held-out MetaWorld tasks, each tested with multiple prompt styles.\\n20–50 closed-loop rollouts per task (approximately 100–150 total evaluation episodes).\\nAdditional synthetic evaluation set with domain randomization (lighting shifts, camera noise, distractors): approximately 50–100 perturbed episodes.\\nIf sim-to-real: small set of real-robot demonstrations collected manually.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"Part II — Architecture Lab 1 Peer Audit\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"em\",null,{\"children\":[\"Source: PR \",[\"$\",\"a\",null,{\"href\":\"https://github.com/arpg/vla-foundations/pull/52\",\"children\":\"#52\"}],\" (krusnim). Scribed by Mel; presented by Lorin. No generative tools used to produce this document.\"]}]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"Lorin: Utilizing Risk Profiles in VLAs\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Goal:\"}],\" Change action outputs based on a risk profile.\\nThis profile should be encoded in an RL policy so the stack is risk-aware.\\nExample: get X close to a person without entering a \\\"risk zone.\\\"\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Data:\"}],\" An \\\"OpenVLA or Octo type dataset,\\\" possibly Open X-Embodiment (OXE).\\nA small collection of simulation data on a robot arm is required for fine-tuning, collected via IsaacSim/IsaacLab.\"]}],\"\\n\",\"$Lf\",\"\\n\",\"$L10\",\"\\n\",\"$L11\",\"\\n\",\"$L12\",\"\\n\",\"$L13\",\"\\n\",\"$L14\",\"\\n\",\"$L15\",\"\\n\",\"$L16\",\"\\n\",\"$L17\",\"\\n\",\"$L18\",\"\\n\",\"$L19\",\"\\n\",\"$L1a\",\"\\n\",\"$L1b\",\"\\n\",\"$L1c\",\"\\n\",\"$L1d\",\"\\n\",\"$L1e\",\"\\n\",\"$L1f\",\"\\n\",\"$L20\",\"\\n\",\"$L21\",\"\\n\",\"$L22\",\"\\n\",\"$L23\",\"\\n\",\"$L24\",\"\\n\",\"$L25\",\"\\n\",\"$L26\",\"\\n\",\"$L27\",\"\\n\",\"$L28\",\"\\n\",\"$L29\",\"\\n\",\"$L2a\",\"\\n\",\"$L2b\",\"\\n\",\"$L2c\",\"\\n\",\"$L2d\",\"\\n\",\"$L2e\",\"\\n\",\"$L2f\",\"\\n\",\"$L30\",\"\\n\",\"$L31\",\"\\n\",\"$L32\",\"\\n\",\"$L33\",\"\\n\",\"$L34\",\"\\n\",\"$L35\",\"\\n\",\"$L36\",\"\\n\",\"$L37\"]\n"])</script><script>self.__next_f.push([1,"f:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Training:\"}],\" Scaling is a major concern.\\nTraining an RL policy and then evaluating will take a while.\\nIt is not necessarily compute-heavy to collect a small dataset and demonstrate one safe and one unsafe trajectory that are meaningfully different.\"]}]\n10:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Discussion:\"}],\"\\nThanush asked about dataset details.\\nIdeally a mix of internet-scale and fine-tuning data; an exact mix has not been determined yet.\\nIf computational issues arise, scaling down to minimum is necessary.\\nThe minimum dataset would be a supervised fine-tuning set created from teleoperation in simulation.\\nThe project starts with a very simple task: designating a risk zone and a safe zone.\"]}]\n11:[\"$\",\"p\",null,{\"children\":\"Soorej asked how the safe/unsafe zone will be validated.\\nThere is a binary classification component, but quantifying how far inside the safe zone the robot is would also be valuable.\\nA full understanding of the distribution of actions and their rewards/costs is the goal.\"}]\n12:[\"$\",\"p\",null,{\"children\":\"Mel asked about the base VLA.\\nProbably OpenVLA, Octo, or SmolVLA — whichever provides easier setup and future scalability (open weights, full robot models).\"}]\n13:[\"$\",\"p\",null,{\"children\":\"Mel asked whether there is a particular safe RL work this draws from.\\nStatistical analysis tools on the RL training stage are applicable: risk-aware PPO implementations, value iteration/Bellman adjustments.\\nA simpler value iteration could be the starting point; distributional RL with PPO is also a strong candidate.\"}]\n14:[\"$\",\"p\",null,{\"children\":\"Thanush asked whether a sensor on the arm would help produce data/safety measurements.\\nAdditional sensors with fixed, rule-based emergency stop policies are valid but redundant.\\nThere are reasons to not rely solely on rule-based vision or proximity sensors.\\nWhen deploying in real life, if the on-arm camera fails, the system still needs to determine what is safe.\"}]\n15:[\"$\",\"h3\",null,{\"children\":\"Thanush: MoE Policy Head for MetaWorld Generalization\"}]\n16:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Goal:\"}],\" Based on TinyVLA, build a VLA stack with a new policy head to learn multiple expert action modules for different manipulation behaviors.\\nTrain on a fragment of MetaWorld tasks; evaluate on related but unseen tasks to determine generalization capabilities.\"]}]\n17:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Data:\"}],\" Sourced from MetaWorld.\\n\",[\"$\",\"strong\",null,{\"children\":\"Training:\"}],\" On a consumer GPU.\"]}]\n18:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Discussion:\"}],\"\\nSoorej asked how \\\"difficulty\\\" of tasks is defined.\\nTraining on easy tasks and testing on difficult ones, and vice versa, should both be evaluated.\\nMetaWorld has ten tasks total; if a model trained to open a drawer cannot open a fridge, that is a generalization failure.\"]}]\n19:[\"$\",\"p\",null,{\"children\":\"Lorin asked about the compute setup.\\nTinyVLA has parameters on the order of millions; a consumer GPU should suffice.\"}]\n1a:[\"$\",\"p\",null,{\"children\":\"Lorin asked whether the plan is to pick an existing architecture like TinyVLA.\\nThe goal is to build something from scratch and train on a dataset.\\nA comparison will then be made after adding the new custom policy head.\"}]\n1b:[\"$\",\"h3\",null,{\"children\":\"Soorej: Apples-to-Apples Policy Comparison\"}]\n1c:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Goal:\"}],\" Compare a diffusion policy, an autoregressive approach, and an RL approach to visuomotor control with identical datasets and architectures — essentially an ablation.\"]}]\n1d:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Data:\"}],\" Unknown; likely Open X-Embodiment.\\n\",[\"$\",\"strong\",null,{\"children\":\"Training:\"}],\" 5–10 GPU hours for each model.\"]}]\n1e:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Discussion:\"}],\"\\nLorin asked about the RL method.\\nPPO or GRPO.\"]}]\n1f:[\"$\",\"p\",null,{\"children\":\"Lorin asked wheth"])</script><script>self.__next_f.push([1,"er flow matching was considered.\\nNot yet, but it is an interesting possibility.\"}]\n20:[\"$\",\"p\",null,{\"children\":\"Mel asked about compute requirements and backbone considerations.\\n5–10 GPU hours per model.\\nThe diffusion backbone will be based on the vision model control paper.\\nFor autoregression, it will be a plain Transformer.\"}]\n21:[\"$\",\"p\",null,{\"children\":\"Thanush asked whether training setups will differ across methods.\\nIdeally no.\"}]\n22:[\"$\",\"p\",null,{\"children\":\"Lorin asked what dataset will be used.\\nOpen X-Embodiment, maybe.\"}]\n23:[\"$\",\"p\",null,{\"children\":\"Lorin asked about major concerns and plan B.\\nMoving to smaller models or a smaller dataset and comparing only RL and autoregression is the fallback.\"}]\n24:[\"$\",\"p\",null,{\"children\":\"Lorin asked how outputs in the action space will be compared.\\nCurrently unsure.\"}]\n25:[\"$\",\"h3\",null,{\"children\":\"Mel: Adversarial Strategic Reasoning in VLAs\"}]\n26:[\"$\",\"p\",null,{\"children\":[\"$\",\"em\",null,{\"children\":\"(Scribed by Soorej)\"}]}]\n27:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Goal:\"}],\" In adversarial multiagent settings, the correct, least-exploitable action outputs are stochastic — but the stochasticity output by a VLA may not match the correct action weights.\\nThe goal is to generate analytically correct trajectories and fine-tune the VLA so that token probabilities align with strategically optimal mixed-action trajectories.\"]}]\n28:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Root model:\"}],\" MiniVLA (or TinyVLA, VQ-BeT).\\n\",[\"$\",\"strong\",null,{\"children\":\"Data:\"}],\" Partially world model data, partially single-agent robot data, partially generated adversarial data.\"]}]\n29:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Discussion:\"}],\"\\nLorin asked whether training is required.\\nYes — fine-tuning with the adversarial data.\\nThe opponent in all cases will be a fixed policy (not a second VLA) to simplify training.\\nThe goal is to avoid being exploited by that fixed opponent.\"]}]\n2a:[\"$\",\"p\",null,{\"children\":\"Lorin asked about expected computational cost.\\nGPUs are available.\\nOpenVLA can apparently be fine-tuned in about a dozen hours; the narrower robot data may reduce the number of training hours needed.\"}]\n2b:[\"$\",\"p\",null,{\"children\":\"Lorin asked for the simplest possible demonstration.\\nA common example is tag; getting more complicated or general than that would be ideal.\\nTag is good because it is very easy to analytically generate mixed probabilistic trajectories.\"}]\n2c:[\"$\",\"p\",null,{\"children\":\"Lorin noted this project seems more complex than the others and asked about a simpler backup plan.\\nOne option: focus only on action tokenization — a potential modification of VQ-BeT where the latent action space focuses on encoding the most strategically relevant actions first.\"}]\n2d:[\"$\",\"h3\",null,{\"children\":\"Overarching Commentary\"}]\n2e:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Load-bearing walls:\"}],\"\\nData is the primary load-bearing wall.\\nFor Lorin and Mel, data generation will be required and difficult to get right.\\nThanush and Soorej will use exclusively existing data — potentially easier but still a bottleneck.\\nSimulation is the shared substrate; none of these projects will be deployed on hardware.\\nInformation decay: all projects simplify more complex problems, losing action information in the process.\\nThis is a particularly sharp problem for Soorej, where action spaces will differ across methods.\"]}]\n2f:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Unresolved engineering question:\"}],\"\\nThe group struggled to identify a single unifying engineering question, given the diversity of projects.\\nGenerating data in simulation is the central problem for action-centric projects (Lorin and Mel).\\nDefining standards for apples-to-apples comparisons is the focus for benchmarking-centric projects (Thanush and Soorej).\\nSharing a general data pipeline for internet-scale and robot data across projects is a potential efficiency gain.\"]}]\n30:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\""])</script><script>self.__next_f.push([1,",null,{\"children\":\"Most robust initial dissolve:\"}],\"\\nNo single most-robust initial dissolve was named.\"]}]\n31:[\"$\",\"hr\",null,{}]\n32:[\"$\",\"h2\",null,{\"children\":\"Part III — Instructor Feedback\"}]\n33:[\"$\",\"blockquote\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"@crheckman\"}],\" — \",[\"$\",\"em\",null,{\"children\":\"To be completed during finals week.\"}]]}],\"\\n\"]}]\n34:[\"$\",\"h3\",null,{\"children\":\"Score\"}]\n35:[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"Student\"}],[\"$\",\"th\",null,{\"children\":\"GitHub\"}],[\"$\",\"th\",null,{\"children\":\"Proposal\"}],[\"$\",\"th\",null,{\"children\":\"Chapter\"}],[\"$\",\"th\",null,{\"children\":\"Code\"}],[\"$\",\"th\",null,{\"children\":\"Presentation\"}],[\"$\",\"th\",null,{\"children\":\"Total\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Thanushraam\"}],[\"$\",\"td\",null,{\"children\":\"@Tr0612\"}],[\"$\",\"td\",null,{\"children\":\"—\"}],[\"$\",\"td\",null,{\"children\":\"—\"}],[\"$\",\"td\",null,{\"children\":\"—\"}],[\"$\",\"td\",null,{\"children\":\"—\"}],[\"$\",\"td\",null,{\"children\":\"—\"}]]}]}]]}]\n36:[\"$\",\"h3\",null,{\"children\":\"Commentary\"}]\n37:[\"$\",\"p\",null,{\"children\":[\"$\",\"em\",null,{\"children\":\"Placeholder for instructor notes.\"}]}]\n"])</script><script>self.__next_f.push([1,"9:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"38:I[27654,[\"/staging/pulls/62/_next/static/chunks/3421e88d40c9134c.js\",\"/staging/pulls/62/_next/static/chunks/fbf372f7eb8336a2.js\"],\"IconMark\"]\n7:null\nb:[[\"$\",\"title\",\"0\",{\"children\":\"Thanushraam (Tr0612): Cross-Task Generalization in Small VLAs — Capstone Running Log - VLA Capstone\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Capstone project report for @Tr0612\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/staging/pulls/62/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$L38\",\"3\",{}]]\n"])</script></body></html>