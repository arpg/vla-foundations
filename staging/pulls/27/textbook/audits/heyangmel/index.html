<!DOCTYPE html><!--J8pNqX2b_C_2UW2xig5ZW--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/staging/pulls/27/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/staging/pulls/27/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="https://hackmd.io/_uploads/B1OfcT0HZe.png" as="image"/><link rel="preload" href="https://hackmd.io/_uploads/BJfrvNk8Wx.png" as="image"/><link rel="preload" href="https://hackmd.io/_uploads/Sk2snE1Ibe.png" as="image"/><link rel="preload" href="https://hackmd.io/_uploads/HkobvekU-g.png" as="image"/><link rel="stylesheet" href="/staging/pulls/27/_next/static/chunks/5828b8010e52ce93.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/staging/pulls/27/_next/static/chunks/e91d669deb91b5ae.js"/><script src="/staging/pulls/27/_next/static/chunks/e416cfb39a40580e.js" async=""></script><script src="/staging/pulls/27/_next/static/chunks/0d359cd46aa68ea7.js" async=""></script><script src="/staging/pulls/27/_next/static/chunks/73ba5f7771557dcc.js" async=""></script><script src="/staging/pulls/27/_next/static/chunks/turbopack-a2daa64265327895.js" async=""></script><script src="/staging/pulls/27/_next/static/chunks/e3f3620ea1ae9685.js" async=""></script><script src="/staging/pulls/27/_next/static/chunks/feb976563fece928.js" async=""></script><script src="/staging/pulls/27/_next/static/chunks/ac6acee8a4924905.js" async=""></script><meta name="next-size-adjust" content=""/><title>Evaluating Vector Quantization for VLA Action Tokenization - VLA Foundations</title><meta name="description" content="RT-1 (2022), VQ-BeT (ICML 2024), MotionLM (2023)"/><link rel="icon" href="/staging/pulls/27/favicon.ico?favicon.0b3bf435.ico" sizes="256x256" type="image/x-icon"/><script src="/staging/pulls/27/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased"><div hidden=""><!--$--><!--/$--></div><div class="flex min-h-screen"><aside class="w-64 border-r border-gray-200 bg-gray-50 p-6 overflow-y-auto h-screen sticky top-0"><div class="mb-8"><a class="block" href="/staging/pulls/27/"><h1 class="text-2xl font-bold text-gray-900">VLA Stack</h1><p class="text-sm text-gray-600 mt-1">Vision-Language-Action</p></a></div><nav class="space-y-1"><div class="text-xs font-semibold text-gray-500 uppercase tracking-wide mb-3">Living Textbook</div><a class="block px-3 py-2 rounded-md text-sm transition-colors text-gray-700 hover:bg-gray-200" href="/staging/pulls/27/textbook/foundations/"><div class="flex items-baseline gap-2"><span class="text-xs text-gray-500">0<!-- -->.</span><span class="flex-1">Foundations: Introduction to the VLA Stack</span></div></a><a class="block px-3 py-2 rounded-md text-sm transition-colors text-gray-700 hover:bg-gray-200" href="/staging/pulls/27/textbook/architectures/"><div class="flex items-baseline gap-2"><span class="text-xs text-gray-500">1<!-- -->.</span><span class="flex-1">Architectures: VLA Model Designs</span></div></a><a class="block px-3 py-2 rounded-md text-sm transition-colors text-gray-700 hover:bg-gray-200" href="/staging/pulls/27/textbook/data/"><div class="flex items-baseline gap-2"><span class="text-xs text-gray-500">2<!-- -->.</span><span class="flex-1">Data: Dataset Construction and Curation</span></div></a><a class="block px-3 py-2 rounded-md text-sm transition-colors text-gray-700 hover:bg-gray-200" href="/staging/pulls/27/textbook/training/"><div class="flex items-baseline gap-2"><span class="text-xs text-gray-500">3<!-- -->.</span><span class="flex-1">Training: Optimization and Learning Methods</span></div></a><a class="block px-3 py-2 rounded-md text-sm transition-colors text-gray-700 hover:bg-gray-200" href="/staging/pulls/27/textbook/evaluation/"><div class="flex items-baseline gap-2"><span class="text-xs text-gray-500">4<!-- -->.</span><span class="flex-1">Evaluation: Metrics and Benchmarking</span></div></a><a class="block px-3 py-2 rounded-md text-sm transition-colors text-gray-700 hover:bg-gray-200" href="/staging/pulls/27/textbook/deployment/"><div class="flex items-baseline gap-2"><span class="text-xs text-gray-500">5<!-- -->.</span><span class="flex-1">Deployment: Production Systems and Scaling</span></div></a><a class="block px-3 py-2 rounded-md text-sm transition-colors text-gray-700 hover:bg-gray-200" href="/staging/pulls/27/textbook/applications/"><div class="flex items-baseline gap-2"><span class="text-xs text-gray-500">6<!-- -->.</span><span class="flex-1">Applications: Real-World Use Cases</span></div></a><a class="block px-3 py-2 rounded-md text-sm transition-colors text-gray-700 hover:bg-gray-200" href="/staging/pulls/27/textbook/future/"><div class="flex items-baseline gap-2"><span class="text-xs text-gray-500">7<!-- -->.</span><span class="flex-1">Future Directions: Open Problems and Research Frontiers</span></div></a></nav><div class="mt-8 pt-8 border-t border-gray-200"><nav class="space-y-1"><a class="block px-3 py-2 rounded-md text-sm text-gray-700 hover:bg-gray-200" href="/staging/pulls/27/reference/">Reference Implementations</a></nav></div></aside><main class="flex-1 flex"><article class="flex-1 max-w-4xl mx-auto px-8 py-12"><div class="prose prose-lg prose-slate max-w-none"><a class="text-sm text-blue-600 hover:text-blue-800 mb-8 inline-block" href="/staging/pulls/27/textbook/audits/">← Back to Audits</a><div class="mb-8"><div class="flex items-center gap-3 mb-4"><span class="text-sm font-medium text-blue-600 bg-blue-50 px-3 py-1 rounded-full">Action Tokenization</span></div><h1 class="text-4xl font-bold text-gray-900 mb-4">Evaluating Vector Quantization for VLA Action Tokenization</h1><p class="text-xl text-gray-600 mb-4">RT-1 (2022), VQ-BeT (ICML 2024), MotionLM (2023)</p><p class="text-gray-700">By <span class="font-medium">heyangmel</span></p></div><h1>Evaluating Vector Quantization for VLA Action Tokenization</h1>
<p>When using vision-language-action (VLA) models for robotics, we typically replace continuous control variables, like the real-valued positions of actuators, with discrete action tokens. This is <strong>action tokenization</strong>. But there is no single, obviously correct way to carry out this tokenization.</p>
<p>In this paper audit, we analyze action tokenization as a systems-level design choice. Our primary focus is the <em>vector quantized behavior transformer</em> (<a href="https://arxiv.org/pdf/2403.03181">VQ-BeT</a>), which uses a method called <em>vector quantization</em> to tokenize actions. On the way, we&#x27;ll discuss some popular alternatives - some newer, some older - focusing on their modeling assumptions and potential failure modes. Then, after a deep dive into VQ-BeT, we&#x27;ll compare all of these options and provide some discussion about ongoing and future action tokenization work.</p>
<hr/>
<h1>[1] Understanding action tokenization</h1>
<p><em>What&#x27;s the core technical challenge?</em></p>
<p>Traditional robot control relies on continuous action spaces that align closely with the underlying physics of robotic systems. Torques, velocities, and end-effector motions are naturally continuous. Classical control theory is built around preserving smoothness, stability, and reactivity under this assumption. But motivated by the success of token-based generative modeling, a growing body of work replaces continuous control with action tokens: latent discrete symbols that are decoded into continuous actions at execution time.</p>
<p>The practice of action discretization is not new. However, in the VLA context, it&#x27;s substantially more important than in the past, credited with stabilizing training, enabling reuse of language-model architectures, and simplifying long-horizon credit assignment. However, it still comes at the fundamental tradeoff of degrading the mechanical precision of a robot. As such, it&#x27;s natural to ask:</p>
<ul>
<li>What assumptions about dynamics, smoothness, and temporal structure make discrete actions viable?</li>
<li>Which failure modes are possible?<!-- -->
<ul>
<li>... and how are they masked by offline datasets and scripted evaluation protocols?</li>
</ul>
</li>
<li>Under what conditions does tokenization reduce complexity?<!-- -->
<ul>
<li>... and when does it merely relocate it into the decoder or execution stack?</li>
</ul>
</li>
</ul>
<hr/>
<h1>[2] The competitors</h1>
<p><em>How has &quot;initial dissolve&quot; of action tokenization evolved over the last few years?</em></p>
<p>Early action tokenizers for VLAs simply quantized actions into discrete bins based on actuator values - a surprisingly effective approach. But since then, there have been some developments.</p>
<p>This section is a combination taxonomy and chronology. We&#x27;ll start by discussing the early approaches that used <strong>simple binning</strong>, and the marginal improvements made in that direction. Then we&#x27;ll cover a well-established family of action tokenizers based on <strong>vector quantization</strong> (VQ). We&#x27;ll cover one particular VQ-based approach, VQ-BeT, in complete detail, as we consider it emblematic of the concerns and lineage of the action quantization literature. Following that, we&#x27;ll briefly discuss <strong>the cutting edge</strong>, forgoing VQ in favor of other ideas.</p>
<p>While we&#x27;ll discuss the benefits and drawbacks of these broad categories as we introduce them, you can also skip <a href="#evaluating-action-tokenizers">straight to our technical analysis</a>.</p>
<hr/>
<h2>The baseline: Simple binning</h2>
<p>This is the most straightforward form of action tokenization: bin the range of continuous actuator commands into discrete values. Typically, actions for each actuator are discretized independently. This was the approach taken by many foundational robotics transformers circa 2022.</p>
<p>Assuming without loss of generality that actuator commands are in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>255</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">[0, 255)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">255</span><span class="mclose">)</span></span></span></span> (as is often seen), the binning approach is mathematically as simple as can be:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>action_token</mtext><mo>=</mo><mo stretchy="false">⌊</mo><mi>a</mi><mo stretchy="false">⌋</mo></mrow><annotation encoding="application/x-tex">\text{action\_token} = \lfloor a \rfloor</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em"></span><span class="mord text"><span class="mord">action_token</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">⌊</span><span class="mord mathnormal">a</span><span class="mclose">⌋</span></span></span></span></span>
<p>Depending on the architecture, these 255 (or so) action tokens might be usable as-is, or (as a hack if available tokens are limited) might overwrite the 255 <em>least used</em> tokens in the upstream language model.</p>
<p>There is some nuance in how binning is applied. <a href="https://arxiv.org/abs/2212.06817">RT-1</a>’s action tokenizer discretized uniformly across the entire action space (based on minimum and maximum values seen in the data) into 256 equal-size bins. This choice was, apparently, good enough: in the corresponding ablation study, they note a -25% success rate delta when this action tokenizer is removed (though no comparison was given with other action tokenization schemes). A near-identical scheme was reused for <a href="https://arxiv.org/abs/2307.15818">RT-2</a> in 2023.</p>
<p>In later 2023, Waymo&#x27;s <a href="https://arxiv.org/pdf/2309.16534">MotionLM</a> introduced some slight modifications, using a &quot;Verlet wrapper&quot; around uniformly binned deltas for each coordinate. In practice, this resulted in a substantial reduction in the number of distinct tokens required, though it was not fully specified how this reduction arose. Later, during work on <a href="https://arxiv.org/pdf/2406.09246">OpenVLA</a> in early 2024, it was noticed that computing bins based on the minimum and maximum actuator values was vulnerable to outliers - though bins were of equal numerical size, the majority of data fell in a subset of bins, so some precision was wasted. To amend this issue, the authors of OpenVLA opted to use a quantile-based approach instead, such that each bin covered the same amount of training data:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>action_token</mtext><mo>=</mo><mo stretchy="false">⌊</mo><mtext>quantile</mtext><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>⋅</mo><mn>255</mn><mo stretchy="false">⌋</mo></mrow><annotation encoding="application/x-tex">\text{action\_token} = \lfloor \text{quantile}(a) \cdot 255 \rfloor</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em"></span><span class="mord text"><span class="mord">action_token</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">⌊</span><span class="mord text"><span class="mord">quantile</span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">255</span><span class="mclose">⌋</span></span></span></span></span>
<p>Why did these simple action tokenizers survive for so long, when tokenizers in other components of the VLA stack were more complex? While it&#x27;s hard to say for certain, we suspect that it was discovered early that performance does not necessarily correlate well with scale in action tokenizers. Binning is good enough in many cases, and choosing a more complex action tokenizer can impact inference times (see <a href="#high-frequency-performance">high-frequency performance</a>).</p>
<p>However, it was long suspected that poor action tokenization prevented dexterous performance in RT-2. Indeed, in 2025, Physical Intelligence released a performance comparison of a &quot;naive&quot; (binning) tokenizer with a new, bespoke alternative (<a href="https://arxiv.org/abs/2501.09747">FAST</a>), suggesting serious deterioration of performance specifically with increased sampling rate:</p>
<p><img src="https://hackmd.io/_uploads/B1OfcT0HZe.png" alt="Performance comparison of naive tokenizer vs FAST"/></p>
<p>As such, recent trends seem to lean away from binning tokenizers - although their simplicity remains compelling.</p>
<hr/>
<h2>The protagonist: Vector quantization and VQ-BeT</h2>
<p>The qualitative shift away from binning-based action tokenizers was a long time coming. By mid-2024, there was work in avoiding binning by instead learning a vector-quantized latent action space and using it as a load-bearing interface for sequence modeling, described as <a href="https://arxiv.org/abs/2403.03181">VQ-BeT</a>.</p>
<p>In this audit, we use VQ-BeT as a particularly interesting case study - not for its optimality (though it performs well in several respects), but because it crystallizes the core design assumptions behind latent action quantization in VLA systems.</p>
<h3>How it works</h3>
<p>VQ-BeT decomposes action generation into two explicitly separated stages: (i) offline action tokenization via residual vector quantization, and (ii) online autoregressive prediction of discrete latent codes conditioned on observations (and optionally goals). This separation reflects a deliberate reorganization of the control stack, in which representation learning, sequence modeling, and continuous execution are assigned distinct roles.</p>
<h4>Stage 1: Chunk tokenization via residual VQ-VAE</h4>
<p>Given a continuous action (or short action chunk) <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mrow><mi>t</mi><mo>:</mo><mi>t</mi><mo>+</mo><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">a_{t:t+n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span></span></span></span>, VQ-BeT first maps it into a latent embedding using an encoder:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>ϕ</mi><mo>:</mo><mi>x</mi><mo>=</mo><mi>ϕ</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mrow><mi>t</mi><mo>:</mo><mi>t</mi><mo>+</mo><mi>n</mi></mrow></msub><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\phi: x=\phi(a_{t:t+n}).</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">.</span></span></span></span></span>
<p>This latent is discretized using <strong>Residual Vector Quantization (RVQ)</strong> (<a href="https://arxiv.org/abs/2107.03312">RVQ</a>), where multiple vector quantizers are applied sequentially. Each quantization layer selects the nearest codebook vector to the remaining residual:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>z</mi><mi>q</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mi>q</mi></msub></munderover><msubsup><mi>z</mi><mi>q</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">z_q(x) = \sum_{i=1}^{N_q} z_q^{(i)},</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3.2143em;vertical-align:-1.2777em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9367em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.4083em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-2.453em;margin-left:-0.044em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span></span>
<p>and</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>z</mi><mi>q</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><msubsup><mi>e</mi><mi>j</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup></munder><msub><mrow><mo fence="true">∥</mo><msup><mi>r</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo>−</mo><msubsup><mi>e</mi><mi>j</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><mo fence="true">∥</mo></mrow><mn>2</mn></msub><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">z_q^{(i)} = \arg\min_{e_j^{(i)}} \left\| r^{(i)} - e_j^{(i)} \right\|_2,</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3211em;vertical-align:-0.3831em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-2.453em;margin-left:-0.044em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.4802em;vertical-align:-1.3302em"></span><span class="mop">ar<span style="margin-right:0.01389em">g</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em"><span style="top:-2.0926em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0591em"><span style="top:-2.2134em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span style="top:-3.0591em;margin-right:0.0714em"><span class="pstrut" style="height:2.5357em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4612em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop">min</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3302em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.15em"><span style="top:-3.15em"><span class="pstrut" style="height:3.8em"></span><span style="width:0.556em;height:1.800em"><svg xmlns="http://www.w3.org/2000/svg" width="0.556em" height="1.800em" viewBox="0 0 556 1800"><path d="M145 15 v585 v600 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v-600 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v600 v585 h43z
M367 15 v585 v600 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v-600 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v600 v585 h43z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.65em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.413em"><span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.15em"><span style="top:-3.15em"><span class="pstrut" style="height:3.8em"></span><span style="width:0.556em;height:1.800em"><svg xmlns="http://www.w3.org/2000/svg" width="0.556em" height="1.800em" viewBox="0 0 556 1800"><path d="M145 15 v585 v600 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v-600 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M188 15 H145 v585 v600 v585 h43z
M367 15 v585 v600 v585 c2.667,10,9.667,15,21,15
c10,0,16.667,-5,20,-15 v-585 v-600 v-585 c-2.667,-10,-9.667,-15,-21,-15
c-10,0,-16.667,5,-20,15z M410 15 H367 v585 v600 v585 h43z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.65em"><span></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-0.2486em"><span style="top:-2.0003em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span></span></span></span></span>
<p>where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>r</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">r^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> denotes the residual after subtracting the codebook vectors selected by previous layers.</p>
<p>The quantized latent is then decoded back into a continuous action via a decoder:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>ψ</mi><mo>:</mo><msub><mover accent="true"><mi>a</mi><mo>^</mo></mover><mrow><mi>t</mi><mo>:</mo><mi>t</mi><mo>+</mo><mi>n</mi></mrow></msub><mo>=</mo><mi>ψ</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>q</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\psi:\hat{a}_{t:t+n} = \psi(z_q(x)).</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">ψ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.9028em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">a</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord mathnormal" style="margin-right:0.03588em">ψ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span><span class="mord">.</span></span></span></span></span>
<p>VQ-BeT uses a small number of residual quantization layers (typically two), interpreting the first as capturing coarse action modes (<em>primary codes</em>) and subsequent layers as encoding finer-grained residual structure (<em>secondary codes</em>).</p>
<h4>Stage 2: Autoregressive prediction of latent action codes</h4>
<p>After training the tokenizer, it is frozen and used to convert actions into discrete codes. A GPT-style transformer is then trained to predict these codes conditioned on recent observations:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo fence="false" stretchy="true" minsize="1.2em" maxsize="1.2em">(</mo><mo stretchy="false">{</mo><msubsup><mi>z</mi><mi>q</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">}</mo><mo>∣</mo><msub><mi>o</mi><mrow><mi>t</mi><mo>−</mo><mi>h</mi><mo>:</mo><mi>t</mi></mrow></msub><mo separator="true">,</mo><mi>g</mi><mo fence="false" stretchy="true" minsize="1.2em" maxsize="1.2em">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">p\big(\{z_q^{(i)}\} \mid o_{t-h:t}, g \big),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3211em;vertical-align:-0.3831em"></span><span class="mord mathnormal">p</span><span class="mord"><span class="delimsizing size1">(</span></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-2.453em;margin-left:-0.044em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em"><span></span></span></span></span></span></span><span class="mclose">}</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">h</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mord"><span class="delimsizing size1">)</span></span><span class="mpunct">,</span></span></span></span></span>
<p>where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span></span></span></span> is an optional goal signal.</p>
<p>Rather than predicting a single token per timestep, the model predicts one categorical distribution per quantization layer. Training loss weights errors in primary code prediction more heavily than secondary codes, reflecting the intended coarse-to-fine structure of the latent space.</p>
<h4>Stage 3: Offset head and continuous correction</h4>
<p>To compensate for the loss of precision introduced by discretization, VQ-BeT adds a continuous <strong>offset head</strong> that predicts a residual correction to the decoded action:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi>a</mi><mo>^</mo></mover><mrow><mi>t</mi><mo>:</mo><mi>t</mi><mo>+</mo><mi>n</mi></mrow></msub><mo>=</mo><mi>ψ</mi><mo stretchy="false">(</mo><msub><mi>z</mi><mi>q</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><msub><mi>ζ</mi><mtext>offset</mtext></msub><mo stretchy="false">(</mo><msub><mi>o</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\hat{a}_{t:t+n} = \psi(z_q(x)) + \zeta_{\text{offset}}(o_t).</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9028em;vertical-align:-0.2083em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">a</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord mathnormal" style="margin-right:0.03588em">ψ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07378em">ζ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0738em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">offset</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">.</span></span></span></span></span>
<p>This offset is trained with a regression loss and applied at execution time, providing a mechanism for fine-grained adjustment while preserving a discrete decision interface.</p>
<hr/>
<p>Taken together, VQ-BeT does not eliminate continuous control, but redistributes it. Discrete latent codes are used to model long-horizon structure and multimodality, while continuous correction is relegated to the decoder and offset pathways. This division of responsibility is central to both the strengths and limitations of vector-quantized action tokenization.</p>
<p><img src="https://hackmd.io/_uploads/BJfrvNk8Wx.png" alt="VQ-BeT overview"/></p>
<h3>Other vector quantization approaches</h3>
<p>Vector quantization has appeared in a range of neighboring contexts, from representation compression to skill abstraction, with substantially different system-level roles. In most prior uses—such as <a href="https://arxiv.org/abs/1711.00937">VQ-VAE</a>-style compression or skill-centric methods like <a href="https://arxiv.org/abs/2407.15840">QueST</a> —quantized latents serve either efficiency or reuse, rather than acting as a direct interface to token-based sequence models.</p>
<p>VQ-BeT distinguishes itself by adopting vector quantization explicitly as an action tokenization mechanism for autoregressive modeling, positioning discrete latent actions as the primary interface between continuous control and sequence prediction. More recent work, such as <a href="https://arxiv.org/abs/2507.01016">VQ-VLA</a>, extends this design by scaling the tokenizer itself, but preserves the same core abstraction introduced by VQ-BeT: discrete latent actions as the primary interface to sequence models.</p>
<p>This framing allows us to treat VQ-BeT as a representative instance of latent action tokenization, and motivates a broader comparative evaluation of action tokenization strategies at the system level.</p>
<h3>Preliminary evaluations</h3>
<p>At a high level, VQ-BeT demonstrates that vector-quantized action representations can support a wide range of behaviors across simulated and real-world robotic tasks. Empirically, the model shows improved multimodal behavior generation and long-horizon stability compared to simple discretization baselines, particularly in offline imitation settings.</p>
<p><img src="https://hackmd.io/_uploads/Sk2snE1Ibe.png" alt="VQ-BeT results figure"/></p>
<p>However, these evaluations are necessarily entangled with other design choices, including backbone architecture, observation encoding, training data composition, and execution-time control strategies. As a result, reported performance gains cannot be attributed to action tokenization in isolation.</p>
<p>Rather than treating these results as definitive evidence for or against vector-quantized action tokenization, we view them as establishing <em>plausibility</em>: VQ-BeT demonstrates that learned discrete latent actions are a viable interface for sequence models in robotics. The more consequential questions—regarding scalability, robustness, control fidelity, and engineering complexity—require evaluation at the system level.</p>
<hr/>
<h2>The cutting edge: New action tokenizers</h2>
<p>Before stepping into that evaluation, we&#x27;ll first note some very recent developments in the area outside VQ-BeT.</p>
<h3>Frequency-space action tokenization</h3>
<p>Earlier, we showed a comparison between a binning tokenizer and a modern &quot;bespoke&quot; tokenizer. That bespoke tokenizer was <em>frequency-space action sequence tokenization</em> (<a href="https://arxiv.org/pdf/2501.09747">FAST</a>), released in early 2025. FAST is based on the <a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform#Formal_definition">discrete cosine transform</a> (DCT), a widely used concept in signal processing (e.g. in JPEG compression; see also <a href="https://ieeexplore.ieee.org/document/125072">IEEE paper</a>). In short, FAST applies the DCT to normalized actions, bins the DCT coefficients, and applies byte-pair encoding:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>a</mi><mtext>norm</mtext></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>2</mn><mo>⋅</mo><mtext>quantile</mtext><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>M</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>DCT</mtext><mo stretchy="false">(</mo><msub><mi>a</mi><mtext>norm</mtext></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>M</mi><mtext>bin</mtext></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mo stretchy="false">⌊</mo><mi>γ</mi><mi>M</mi><mo stretchy="false">⌋</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mtext>action_tokens</mtext></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>BPE</mtext><mo stretchy="false">(</mo><msub><mi>M</mi><mtext>bin</mtext></msub><mo separator="true">,</mo><mi>ϕ</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
a_{\text{norm}} &amp;= 2 \cdot \text{quantile}(a) - 1 \\
M &amp;= \text{DCT}(a_{\text{norm}}) \\
M_{\text{bin}} &amp;= \lfloor \gamma M \rfloor \\
\text{action\_tokens} &amp;= \text{BPE}(M_{\text{bin}}, \phi)
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:6em;vertical-align:-2.75em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.25em"><span style="top:-5.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">norm</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">bin</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-0.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord">action_tokens</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.75em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.25em"><span style="top:-5.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord text"><span class="mord">quantile</span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord">1</span></span></span><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord text"><span class="mord">DCT</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">norm</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mopen">⌊</span><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mclose">⌋</span></span></span><span style="top:-0.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord text"><span class="mord">BPE</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">bin</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">ϕ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.75em"><span></span></span></span></span></span></span></span></span></span></span></span>
<p><img src="https://hackmd.io/_uploads/HkobvekU-g.png" alt="FAST diagram"/></p>
<p>There are two parameters here: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05556em">γ</span></span></span></span>, which controls the resolution of the bins for the DCT coefficients, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">ϕ</span></span></span></span>, the BPE codebook, which must be learned. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">a</span></span></span></span>, here, is generally an action chunk rather than a single action.</p>
<p>FAST is a learned tokenizer. The same paper also provides FAST+, an ostensibly universal pretraining of FAST on a wide variety of robot morphologies. VQ-BeT, already discussed, is learned as well. But it remains an open question whether training action tokenizers is always practical or convenient, and work continues on non-trained tokenizers. Late 2025 also saw the release of <a href="https://arxiv.org/pdf/2506.06072">BEAST</a>, a no-learning, B-spline-based action tokenizer.</p>
<h3>Actions in continuous space</h3>
<p>Can we avoid having to use discrete actions entirely?</p>
<p>This remains an open question. In late 2024, there was some significant work (<a href="https://arxiv.org/abs/2409.12514">arXiv:2409.12514</a>) involving the usage of diffusion models to avoid tokenizing actions at all. The approach, taken as part of an optimized fine-tuning regime, also yielded a success rate increase in <a href="https://arxiv.org/pdf/2502.19645">OpenVLA-OFT</a>. Initially, <a href="https://arxiv.org/html/2410.24164v1">the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> model used a similar approach</a>... but is outperformed in some respects by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>-FAST, which uses the FAST action tokenizer.</p>
<p>We won&#x27;t go into the details of these methods in this audit, but we will provide some general analysis of the pragmatism of using such methods in comparison to traditional action tokenization.</p>
<hr/>
<a id="evaluating-action-tokenizers"></a>
<h1>[4] Evaluating action tokenizers</h1>
<p>Our evaluation covers three major contexts: action tokenizers as <em>scalable components</em>, as <em>real-world systems</em>, and as <em>engineered mechanisms</em>, focusing respectively on the difficulties of scaling, running, and developing models based on these action tokenizers.</p>
<p>Unfortunately, action tokenizers are not conveniently separated from other components of VLA models - often they are bundled with other iterative improvements. As such, it&#x27;s misleading to provide strict quantitative comparisons based solely on publicly available data. In a few places, we use a rough ranking system to provide our first-principles expectations, based on the color-coded system sometimes seen in hardware reviews: 🔵 denotes &quot;best in class,&quot; 🟢 &quot;good,&quot; 🟡 &quot;situational&quot; or &quot;outdated,&quot; and 🔴 &quot;best avoided.&quot;</p>
<p>Our contenders are as follows:</p>
<table><thead><tr><th>Type</th><th>Action tokenization approach</th><th>Representative</th><th>Release</th></tr></thead><tbody><tr><td>Binning</td><td>Naive binning</td><td>RT-2</td><td>2023</td></tr><tr><td>Binning</td><td>Quantile binning</td><td>OpenVLA</td><td>2024</td></tr><tr><td>VQ</td><td>Residual VQ-VAE</td><td>VQ-BeT</td><td>2024</td></tr><tr><td>DCT</td><td>FAST</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>-FAST</td><td>2025</td></tr><tr><td>None</td><td>Diffusion / flow matching</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></td><td>2024</td></tr></tbody></table>
<hr/>
<h2>As real-world systems</h2>
<p>From the perspective of technical auditing, we first focus on the role of action tokenization in the deployment of the system in the real world. When deployed on physical robots, action tokenizers define more than a representational interface—they define how control authority, feedback, and error correction are distributed across the VLA stack. Discretizing actions necessarily introduces delay, abstraction, or loss of metric structure, and different tokenization strategies make fundamentally different assumptions about when and where these costs can be absorbed.</p>
<p>In this section, we audit action tokenizers under real-world constraints such as latency, high-frequency control, contact dynamics, and partial observability. Rather than asking whether a tokenizer can generate plausible actions, we ask where precise control is enforced, how feedback is incorporated, and which failures are structurally invisible to the model’s decision-making process. These questions determine whether a tokenization strategy remains viable outside scripted evaluation settings.</p>
<h3>Architectural lock-in and control philosophy</h3>
<p>Action tokenization fixes architectural commitments before learning begins: it determines where control authority, precision, and feedback are expected to reside in the VLA stack, and constrains which modeling paradigms are viable downstream.</p>
<ul>
<li><strong>Primitive discretization</strong> places control precision directly on the sequence model.</li>
<li><strong>Latent action tokenization</strong> shifts it to decoders and execution-time correction.</li>
<li><strong>Continuous-action approaches</strong> retain it within the policy itself.</li>
</ul>
<p>These choices are not interchangeable. Each commits the system to a different distribution of responsibility, shaping which errors can be corrected downstream and which failures are structural rather than incidental.</p>
<a id="high-frequency-performance"></a>
<h3>High-frequency performance</h3>
<p>High-frequency control exposes where tokenization delays or abstracts feedback. Discrete action tokens necessarily operate at a coarser temporal granularity than physical dynamics, forcing systems to assume that short-horizon correction can be deferred or handled outside the tokenized decision loop.</p>
<p>Under these conditions, different tokenization strategies fail differently. Primitive discretization degrades precision as update rates increase; latent action tokenization relies on decoders or offset pathways to absorb rapid corrections; continuous-action approaches retain immediate feedback at the cost of heavier computation and tighter coupling. Performance at high frequency therefore reflects not model capacity, but whether the tokenization boundary aligns with the timescale at which control errors must be corrected.</p>
<ul>
<li>🔵 <strong>DCT (FAST):</strong> FAST <em>should</em> be the clear candidate for &quot;best in class,&quot; given that it&#x27;s designed for high-frequency scenarios. And indeed, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>-FAST quantitatively outperforms OpenVLA-style binning at high frequencies, but not because FAST is faster at inference. The idea is that action chunks are heavily temporally correlated, which diminishes the effectiveness of the next-token prediction objective (which might lead to simply repeating the tokens). But <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>-FAST is actually <em>slower</em> at inference than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>—apparently due to an overreliance on autoregressive decoding. We ultimately chose to award it the &quot;best in class&quot; anyway based on recent work from Physical Intelligence working around that issue (<a href="https://www.pi.website/research/real_time_chunking">Real-time Chunking</a>).</li>
<li>🟢 <strong>Residual VQ-VAE:</strong> Vector quantization is surprisingly fast. This is one of the improvements leveraged by <a href="https://ai.stanford.edu/blog/minivla/">MiniVLA</a> (Dec. 2024) to reach OpenVLA-level performance at 2.5× the speed.</li>
<li>🟢 <strong>Diffusion:</strong> While diffusion methods were once thought to be too slow for high-frequency control, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> reaches appreciable frequencies under continuous actions. Aggressive action chunking seems to play a role.</li>
<li>🟡 <strong>Quantile binning:</strong> OpenVLA can run acceptably with 4-bit precision, and we suspect that this is partially possible because this action quantization makes better use of the available number of action tokens. However, even in 4-bit precision the frequency is fairly slow, and we would expect the tradeoffs with respect to dexterity to be rather severe.</li>
<li>🔴 <strong>Naive binning:</strong> RT-2 is slow, mostly for reasons upstream of action tokenization, but it does play a role. While the action tokenization scheme is simple and therefore nominally fast, one might observe that failing to meaningfully compress actions at the token level implies some amount of unnecessary bloat and slowdown in action representation.</li>
</ul>
<h3>Semantic-motor gaps and error attribution</h3>
<p>Action tokenization mediates the mapping from semantic intent to motor execution, creating a gap in which high-level decisions may be correct while physical outcomes are not. This gap is unavoidable in VLA systems, but different tokenization strategies assign responsibility for resolving it to different components of the stack.</p>
<p>With primitive discretization, the sequence model must implicitly learn motor semantics it is poorly suited to represent. Latent action tokenization shifts this burden to decoders and execution-time correction, assuming that semantic errors can be compensated downstream. Continuous-action approaches keep semantic and motor variables coupled, reducing abstraction but preserving accountability. The key distinction is not whether misalignment occurs, but where the system expects it to be resolved—and which component is blamed when it is not.</p>
<h3>Failure modes</h3>
<p>Some failures introduced by action tokenization are structurally invisible to training objectives. When discretization abstracts away timing, contact, or fine-grained feedback, the resulting errors may not appear in token-level losses or imitation metrics, even though they may be obvious at execution time. The following failures are not implementation bugs, but consequences of information that never crosses the action tokenization interface.</p>
<ul>
<li><strong>Dexterous manipulation:</strong> This is the most straightforward and commonly recognized failure mode, caused when there is too little precision in the action token vocabulary to specify very precise motions.</li>
<li><strong>Literal actuator awareness:</strong> Most of the time, natural language is substantially vaguer than motion, so action tokens are sufficient to represent most desired motions. But if a (byzantine) roboticist were to prompt, in natural language, &quot;set gripper to state 50,&quot; there is no guarantee that the instruction would be exactly executed as requested. (In fact, if the fine-tuning dataset used refers primarily to gross actions, as many do, there is no guarantee that the system would associate a &quot;gripper&quot; language token with a gripper action token at all.)</li>
<li><strong>Token conflation:</strong> Few papers discuss in detail how non-action tokens are masked out of the output, if they happen to be generated erroneously.<!-- -->
<ul>
<li>Inversely, OpenVLA (and potentially other LLaMA-backed VLAs) apply a hack when the number of action tokens (bins) exceeds the number of available extra tokens: they overwrite the <em>least used</em> language tokens. They do not specify how the upstream tokenizer is made aware of this. While minor, this choice could potentially result in action tokens being unexpectedly received as input.</li>
</ul>
</li>
<li><strong>Action token stasis:</strong> For trained action tokenizers like VQ-VAE, it&#x27;s particularly important that the training data are representative of all reasonable action chunks. Introducing a new motion may require restructuring the entire latent space.</li>
</ul>
<h3>Scaling with respect to data</h3>
<p>From a scaling perspective, an action tokenizer should function as a reusable abstraction rather than a task-specific artifact. Scaling stresses the tokenization boundary first: as data diversity, model capacity, and deployment scope increase, weaknesses in how actions are abstracted tend to amplify rather than average out. The question is whether scaling reduces control error, or merely relocates it elsewhere in the system.</p>
<ul>
<li>🔵 <strong>Residual VQ:</strong> The performance of VQ-BeT seems to diminish only marginally with the size of the VQ codebook, according to the VQ-BeT paper, which is an exciting data-scaling result when it is the complexity of the robot data (not necessarily the amount) that is scaled. Training the tokenizer does not appear to be a terrible inconvenience. (It could potentially be done with simulated data, at least for gross quantization in the primary VQ-residual layer.)</li>
<li>🟢 <strong>DCT (FAST):</strong> FAST comes with a fantastic promise: that it (FAST+ specifically) can be applied as an action tokenizer for any VLA, no modifications necessary. Whether it delivers on this promise seems like an open question to us. FAST+ required a tremendous amount of robot data to train (1M trajectories across dozens of embodiments), and it&#x27;s difficult to imagine acquiring even more should that prove to be insufficient for any particular morphology.</li>
<li>🟡 <strong>Diffusion (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>):</strong> It&#x27;s not possible to separately train an action tokenizer in this setup, leaving one completely at the mercy of training a flow-matching model.</li>
</ul>
<p>Binning is a trainingless approach, so we consider mostly the ways in which those schemes affect the data efficiency of the entire pipeline.</p>
<ul>
<li>🔴 <strong>Naive binning (RT-2):</strong> While it worked well enough at the time, RT-2&#x27;s naive action tokenizer is vulnerable to outliers, effectively reducing the richness of the data used for fine-tuning. The individual-actuator tokenization also fails to exploit correlations between actuators, which is a shame, since the authors note that the robot dataset on which RT-2 is fine-tuned is insufficient to allow for acquiring new motion skills.</li>
<li>🟡 <strong>Quantile binning (OpenVLA):</strong> An improvement on the naive approach, but still done per-actuator.</li>
</ul>
<h3>Scaling with respect to compute and parameters</h3>
<ul>
<li>🔵 <strong>Diffusion:</strong> At the core interface level, action discretization is a fundamentally lossy layer. It also hides some embodiment knowledge from the robot during fine-tuning, in that only the action tokens, not the actions themselves, are legible. As such, we find a continuous-output approach to be compelling specifically in the situation where compute is plentiful (where it could otherwise be wasted at this lossy boundary).</li>
<li>🟡 <strong>Residual VQ, DCT:</strong> We don&#x27;t see any particular distinguishing factors here.</li>
<li>🔴 <strong>Binning:</strong> Has only trivial parameters, and no amount of compute will make better use of them. In theory, if compute resources were to far outweigh any other, a very large number of bins could be used to alleviate some issues here, but it&#x27;s difficult to imagine a world where compute is so plentiful that it&#x27;s not even marginally worthwhile to reduce the number of action tokens needed.</li>
</ul>
<hr/>
<h1>[5] Bottom line</h1>
<p>Our overall final word on which action tokenizer you should use depends on the context, which we hope will also illuminate the fundamental tradeoffs involved.</p>
<ul>
<li><strong>If you&#x27;re aiming for small and fast:</strong> Start with a VQ-VAE-based method and alter as needed. It&#x27;s representative and not too opaque. Don&#x27;t forget action chunking.</li>
<li><strong>If you&#x27;re hyperscaling / hypergeneralizing:</strong> Why discretize actions at all? It will only be a bottleneck to dexterity. If you really need a tokenizer and you want something suitably general, try FAST+.</li>
<li><strong>If you need &quot;good enough&quot; right now, and you don&#x27;t have data to spare:</strong> If FAST(+) works, use that; it&#x27;ll be much more effective at high frequencies and precisions. Otherwise, binning was good enough for RT-2.</li>
</ul>
<h3>Truly foundational vs marginal gain</h3>
<p><strong>We think VQ-BeT qualifies as foundational.</strong> In the face of FAST, BEAST, and other new action tokenizers, it might not be strictly the best, but it did mark a turning point in seriously considering how action tokenization affects VLA performance. That said, it&#x27;s unclear whether VQ itself will persist as a compelling form of action tokenization, or even whether we will continue to discretize actions at all.</p>
<h2>For further discussion</h2>
<p>This audit is limited in its scope - you can help by commenting on it (see the repo discussion threads if available). In particular, in potential future versions, we&#x27;d like to discuss:</p>
<ul>
<li>Action chunking, in its entirety.</li>
<li>More details on FAST (particularly on its training).</li>
<li>Further discussion on how chosen backbones affect the choice of action tokenization (if at all).</li>
</ul>
<hr/>
<h1>[6] References</h1>
<h2>Binning-based action tokenization</h2>
<ol>
<li>Brohan, A., et al. (2022). <em>RT-1: Robotics Transformer for Real-World Control at Scale.</em> arXiv:2212.06817.</li>
<li>Brohan, A., et al. (2023). <em>RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control.</em> arXiv:2307.15818.</li>
<li>Shi, W., Zhao, H., Liu, Y., et al. (2023). <em>MotionLM: Multi-Agent Motion Forecasting as Language Modeling.</em> arXiv:2309.16534.</li>
<li>Kim, S., Liu, M., He, T., et al. (2024). <em>OpenVLA: An Open-Source Vision-Language-Action Model.</em> arXiv:2406.09246.</li>
<li>Kim, S., Liu, M., He, T., et al. (2025). <em>OpenVLA-OFT: Efficient Online Fine-Tuning for Vision-Language-Action Models.</em> arXiv:2502.19645.</li>
</ol>
<h2>Vector-quantized latent action tokenization</h2>
<ol>
<li>Lee, S., Wang, Y., Etukuru, H., Kim, H. J., Shafiullah, N. M. M., &amp; Pinto, L. (2024). <em>VQ-BeT: Behavior Generation with Latent Actions.</em> ICML 2024 (Spotlight).</li>
<li>Shafiullah, N. M. M., Pinto, L., et al. (2022). <em>BeT: Imitation Learning with Latent Actions.</em> arXiv:2206.11251.</li>
<li>van den Oord, A., Vinyals, O., &amp; Kavukcuoglu, K. (2017). <em>Neural Discrete Representation Learning.</em> NeurIPS 2017.</li>
<li>Zeghidour, N., Pueyo, A., Tagliasacchi, M., &amp; Tagliasacchi, M. (2021). <em>SoundStream: An End-to-End Neural Audio Codec.</em> IEEE/ACM TASLP (2021).</li>
<li>Wang, Y., Zhu, H., Liu, M., Yang, J., Fang, H.-S., &amp; He, T. (2025). <em>VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers.</em> ICCV 2025.</li>
<li>Mete, S., Saxena, S., Isik, B., Geng, J., Ermon, S., &amp; Shafiullah, N. M. M. (2024). <em>QueST: Self-Supervised Skill Abstractions for Learning Continuous Control.</em> NeurIPS 2024.</li>
<li>Wu, J., et al. (2024). <em>MiniVLA: A Lightweight Vision-Language-Action Model.</em> Stanford AI Lab Blog.</li>
<li>Li, Y., et al. (2024). <em>3D-VLA: 3D-Aware Vision-Language-Action Models for Robotic Manipulation.</em> arXiv:2403.09631.</li>
</ol>
<h2>Signal-space and continuous-action alternatives</h2>
<ol>
<li>Ding, Y., Li, X., Xu, D., et al. (2025). <em>FAST: Frequency-Space Action Sequence Tokenization for Robotic Control.</em> arXiv:2501.09747.</li>
<li>Black, K., Brown, N., Xia, F., et al. (2024). <em><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>π</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: A Vision-Language-Action Model with Continuous Control.</em> arXiv:2410.24164.</li>
<li>Zhang, Y., Liu, Z., Xu, Y., et al. (2025). <em>BEAST: B-Spline Encoding for Action Sequence Tokenization.</em> arXiv:2506.06072.</li>
</ol><div class="mt-12 pt-8 border-t border-gray-200"><a class="text-blue-600 hover:text-blue-800 font-medium" href="/staging/pulls/27/textbook/audits/">← Back to All Audits</a></div></div></article><aside class="hidden xl:block w-64 border-l border-gray-200 bg-gray-50 p-6 overflow-y-auto h-screen sticky top-0"><div class="text-xs font-semibold text-gray-500 uppercase tracking-wide mb-3">On This Page</div><div class="text-sm text-gray-600"><p class="text-xs italic">Table of contents</p></div></aside></main></div><!--$--><!--/$--><script src="/staging/pulls/27/_next/static/chunks/e91d669deb91b5ae.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[69133,[\"/staging/pulls/27/_next/static/chunks/e3f3620ea1ae9685.js\",\"/staging/pulls/27/_next/static/chunks/feb976563fece928.js\"],\"default\"]\n3:I[13309,[\"/staging/pulls/27/_next/static/chunks/e3f3620ea1ae9685.js\",\"/staging/pulls/27/_next/static/chunks/feb976563fece928.js\"],\"default\"]\n5:I[64414,[\"/staging/pulls/27/_next/static/chunks/e3f3620ea1ae9685.js\",\"/staging/pulls/27/_next/static/chunks/feb976563fece928.js\"],\"OutletBoundary\"]\n6:\"$Sreact.suspense\"\n8:I[64414,[\"/staging/pulls/27/_next/static/chunks/e3f3620ea1ae9685.js\",\"/staging/pulls/27/_next/static/chunks/feb976563fece928.js\"],\"ViewportBoundary\"]\na:I[64414,[\"/staging/pulls/27/_next/static/chunks/e3f3620ea1ae9685.js\",\"/staging/pulls/27/_next/static/chunks/feb976563fece928.js\"],\"MetadataBoundary\"]\nc:I[37602,[],\"default\"]\n:HL[\"/staging/pulls/27/_next/static/chunks/5828b8010e52ce93.css\",\"style\"]\n:HL[\"/staging/pulls/27/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/staging/pulls/27/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"J8pNqX2b-C_2UW2xig5ZW\",\"c\":[\"\",\"textbook\",\"audits\",\"heyangmel\",\"\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"textbook\",{\"children\":[\"audits\",{\"children\":[[\"slug\",\"heyangmel\",\"c\"],{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/staging/pulls/27/_next/static/chunks/5828b8010e52ce93.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",[[\"$\",\"script\",\"script-0\",{\"src\":\"/staging/pulls/27/_next/static/chunks/ac6acee8a4924905.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L5\",null,{\"children\":[\"$\",\"$6\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@7\"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false]},null,false,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$La\",null,{\"children\":[\"$\",\"$6\",null,{\"name\":\"Next.Metadata\",\"children\":\"$Lb\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$c\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"d:I[14579,[\"/staging/pulls/27/_next/static/chunks/ac6acee8a4924905.js\"],\"AuditLayout\"]\ne:I[60219,[\"/staging/pulls/27/_next/static/chunks/ac6acee8a4924905.js\"],\"\"]\n"])</script><script>self.__next_f.push([1,"4:[\"$\",\"$Ld\",null,{\"chapters\":[{\"title\":\"Foundations: Introduction to the VLA Stack\",\"chapter\":0,\"description\":\"Foundational concepts for Vision-Language-Action systems in robotics\",\"slug\":\"foundations\"},{\"title\":\"Architectures: VLA Model Designs\",\"chapter\":1,\"description\":\"Model architectures, multi-modal encoders, and policy networks for robotics\",\"slug\":\"architectures\"},{\"title\":\"Data: Dataset Construction and Curation\",\"chapter\":2,\"description\":\"Data collection, annotation strategies, and quality assurance for robotics\",\"slug\":\"data\"},{\"title\":\"Training: Optimization and Learning Methods\",\"chapter\":3,\"description\":\"Training strategies, fine-tuning, and optimization for robotic control\",\"slug\":\"training\"},{\"title\":\"Evaluation: Metrics and Benchmarking\",\"chapter\":4,\"description\":\"Success metrics, safety validation, and benchmarking protocols for VLA systems\",\"slug\":\"evaluation\"},{\"title\":\"Deployment: Production Systems and Scaling\",\"chapter\":5,\"description\":\"From semantic supervision to safety-critical validation for autonomous fleets\",\"slug\":\"deployment\"},{\"title\":\"Applications: Real-World Use Cases\",\"chapter\":6,\"description\":\"Case studies and practical applications of VLA systems across domains\",\"slug\":\"applications\"},{\"title\":\"Future Directions: Open Problems and Research Frontiers\",\"chapter\":7,\"description\":\"Emerging trends, unsolved challenges, and the path forward for VLA research\",\"slug\":\"future\"}],\"children\":[[\"$\",\"$Le\",null,{\"href\":\"/textbook/audits\",\"className\":\"text-sm text-blue-600 hover:text-blue-800 mb-8 inline-block\",\"children\":\"← Back to Audits\"}],false,[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-3 mb-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-sm font-medium text-blue-600 bg-blue-50 px-3 py-1 rounded-full\",\"children\":\"Action Tokenization\"}],false]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold text-gray-900 mb-4\",\"children\":\"Evaluating Vector Quantization for VLA Action Tokenization\"}],[\"$\",\"p\",null,{\"className\":\"text-xl text-gray-600 mb-4\",\"children\":\"RT-1 (2022), VQ-BeT (ICML 2024), MotionLM (2023)\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-700\",\"children\":[\"By \",[\"$\",\"span\",null,{\"className\":\"font-medium\",\"children\":\"heyangmel\"}]]}]]}],\"$Lf\",[\"$\",\"div\",null,{\"className\":\"mt-12 pt-8 border-t border-gray-200\",\"children\":[\"$\",\"$Le\",null,{\"href\":\"/textbook/audits\",\"className\":\"text-blue-600 hover:text-blue-800 font-medium\",\"children\":\"← Back to All Audits\"}]}]]}]\n"])</script><script>self.__next_f.push([1,"f:[[\"$\",\"h1\",null,{\"children\":\"Evaluating Vector Quantization for VLA Action Tokenization\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"When using vision-language-action (VLA) models for robotics, we typically replace continuous control variables, like the real-valued positions of actuators, with discrete action tokens. This is \",[\"$\",\"strong\",null,{\"children\":\"action tokenization\"}],\". But there is no single, obviously correct way to carry out this tokenization.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"In this paper audit, we analyze action tokenization as a systems-level design choice. Our primary focus is the \",[\"$\",\"em\",null,{\"children\":\"vector quantized behavior transformer\"}],\" (\",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/pdf/2403.03181\",\"children\":\"VQ-BeT\"}],\"), which uses a method called \",[\"$\",\"em\",null,{\"children\":\"vector quantization\"}],\" to tokenize actions. On the way, we'll discuss some popular alternatives - some newer, some older - focusing on their modeling assumptions and potential failure modes. Then, after a deep dive into VQ-BeT, we'll compare all of these options and provide some discussion about ongoing and future action tokenization work.\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"[1] Understanding action tokenization\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"em\",null,{\"children\":\"What's the core technical challenge?\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Traditional robot control relies on continuous action spaces that align closely with the underlying physics of robotic systems. Torques, velocities, and end-effector motions are naturally continuous. Classical control theory is built around preserving smoothness, stability, and reactivity under this assumption. But motivated by the success of token-based generative modeling, a growing body of work replaces continuous control with action tokens: latent discrete symbols that are decoded into continuous actions at execution time.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The practice of action discretization is not new. However, in the VLA context, it's substantially more important than in the past, credited with stabilizing training, enabling reuse of language-model architectures, and simplifying long-horizon credit assignment. However, it still comes at the fundamental tradeoff of degrading the mechanical precision of a robot. As such, it's natural to ask:\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"What assumptions about dynamics, smoothness, and temporal structure make discrete actions viable?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Which failure modes are possible?\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"... and how are they masked by offline datasets and scripted evaluation protocols?\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Under what conditions does tokenization reduce complexity?\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"... and when does it merely relocate it into the decoder or execution stack?\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h1\",null,{\"children\":\"[2] The competitors\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"em\",null,{\"children\":\"How has \\\"initial dissolve\\\" of action tokenization evolved over the last few years?\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Early action tokenizers for VLAs simply quantized actions into discrete bins based on actuator values - a surprisingly effective approach. But since then, there have been some developments.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"This section is a combination taxonomy and chronology. We'll start by discussing the early approaches that used \",[\"$\",\"strong\",null,{\"children\":\"simple binning\"}],\", and the marginal improvements made in that direction. Then we'll cover a well-established family of action tokenizers based on \",\"$L10\",\" (VQ). We'll cover one particular VQ-based approach, VQ-BeT, in complete detail, as we consider it emblematic of the concerns and lineage of the action quantization literature. Following that, we'll briefly discuss \",\"$L11\",\", forgoing VQ in favor of other ideas.\"]}],\"\\n\",\"$L12\",\"\\n\",\"$L13\",\"\\n\",\"$L14\",\"\\n\",\"$L15\",\"\\n\",\"$L16\",\"\\n\",\"$L17\",\"\\n\",\"$L18\",\"\\n\",\"$L19\",\"\\n\",\"$L1a\",\"\\n\",\"$L1b\",\"\\n\",\"$L1c\",\"\\n\",\"$L1d\",\"\\n\",\"$L1e\",\"\\n\",\"$L1f\",\"\\n\",\"$L20\",\"\\n\",\"$L21\",\"\\n\",\"$L22\",\"\\n\",\"$L23\",\"\\n\",\"$L24\",\"\\n\",\"$L25\",\"\\n\",\"$L26\",\"\\n\",\"$L27\",\"\\n\",\"$L28\",\"\\n\",\"$L29\",\"\\n\",\"$L2a\",\"\\n\",\"$L2b\",\"\\n\",\"$L2c\",\"\\n\",\"$L2d\",\"\\n\",\"$L2e\",\"\\n\",\"$L2f\",\"\\n\",\"$L30\",\"\\n\",\"$L31\",\"\\n\",\"$L32\",\"\\n\",\"$L33\",\"\\n\",\"$L34\",\"\\n\",\"$L35\",\"\\n\",\"$L36\",\"\\n\",\"$L37\",\"\\n\",\"$L38\",\"\\n\",\"$L39\",\"\\n\",\"$L3a\",\"\\n\",\"$L3b\",\"\\n\",\"$L3c\",\"\\n\",\"$L3d\",\"\\n\",\"$L3e\",\"\\n\",\"$L3f\",\"\\n\",\"$L40\",\"\\n\",\"$L41\",\"\\n\",\"$L42\",\"\\n\",\"$L43\",\"\\n\",\"$L44\",\"\\n\",\"$L45\",\"\\n\",\"$L46\",\"\\n\",\"$L47\",\"\\n\",\"$L48\",\"\\n\",\"$L49\",\"\\n\",\"$L4a\",\"\\n\",\"$L4b\",\"\\n\",\"$L4c\",\"\\n\",\"$L4d\",\"\\n\",\"$L4e\",\"\\n\",\"$L4f\",\"\\n\",\"$L50\",\"\\n\",\"$L51\",\"\\n\",\"$L52\",\"\\n\",\"$L53\",\"\\n\",\"$L54\",\"\\n\",\"$L55\",\"\\n\",\"$L56\",\"\\n\",\"$L57\",\"\\n\",\"$L58\",\"\\n\",\"$L59\",\"\\n\",\"$L5a\",\"\\n\",\"$L5b\",\"\\n\",\"$L5c\",\"\\n\",\"$L5d\",\"\\n\",\"$L5e\",\"\\n\",\"$L5f\",\"\\n\",\"$L60\",\"\\n\",\"$L61\",\"\\n\",\"$L62\",\"\\n\",\"$L63\",\"\\n\",\"$L64\",\"\\n\",\"$L65\",\"\\n\",\"$L66\",\"\\n\",\"$L67\",\"\\n\",\"$L68\",\"\\n\",\"$L69\",\"\\n\",\"$L6a\",\"\\n\",\"$L6b\",\"\\n\",\"$L6c\",\"\\n\",\"$L6d\",\"\\n\",\"$L6e\",\"\\n\",\"$L6f\",\"\\n\",\"$L70\",\"\\n\",\"$L71\",\"\\n\",\"$L72\",\"\\n\",\"$L73\",\"\\n\",\"$L74\",\"\\n\",\"$L75\",\"\\n\",\"$L76\",\"\\n\",\"$L77\",\"\\n\",\"$L78\",\"\\n\",\"$L79\",\"\\n\",\"$L7a\",\"\\n\",\"$L7b\",\"\\n\",\"$L7c\",\"\\n\",\"$L7d\",\"\\n\",\"$L7e\",\"\\n\",\"$L7f\",\"\\n\",\"$L80\",\"\\n\",\"$L81\",\"\\n\",\"$L82\",\"\\n\",\"$L83\",\"\\n\",\"$L84\"]\n"])</script><script>self.__next_f.push([1,":HL[\"https://hackmd.io/_uploads/B1OfcT0HZe.png\",\"image\"]\n:HL[\"https://hackmd.io/_uploads/BJfrvNk8Wx.png\",\"image\"]\n:HL[\"https://hackmd.io/_uploads/Sk2snE1Ibe.png\",\"image\"]\n:HL[\"https://hackmd.io/_uploads/HkobvekU-g.png\",\"image\"]\n10:[\"$\",\"strong\",null,{\"children\":\"vector quantization\"}]\n11:[\"$\",\"strong\",null,{\"children\":\"the cutting edge\"}]\n12:[\"$\",\"p\",null,{\"children\":[\"While we'll discuss the benefits and drawbacks of these broad categories as we introduce them, you can also skip \",[\"$\",\"a\",null,{\"href\":\"#evaluating-action-tokenizers\",\"children\":\"straight to our technical analysis\"}],\".\"]}]\n13:[\"$\",\"hr\",null,{}]\n14:[\"$\",\"h2\",null,{\"children\":\"The baseline: Simple binning\"}]\n15:[\"$\",\"p\",null,{\"children\":\"This is the most straightforward form of action tokenization: bin the range of continuous actuator commands into discrete values. Typically, actions for each actuator are discretized independently. This was the approach taken by many foundational robotics transformers circa 2022.\"}]\n16:[\"$\",\"p\",null,{\"children\":[\"Assuming without loss of generality that actuator commands are in \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"[\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mn\",null,{\"children\":\"255\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"[0, 255)\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"[\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"0\"}],[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"255\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]}]]}],\" (as is often seen), the binning approach is mathematically as simple as can be:\"]}]\n"])</script><script>self.__next_f.push([1,"17:[\"$\",\"span\",null,{\"className\":\"katex-display\",\"children\":[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mtext\",null,{\"children\":\"action_token\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"⌊\"}],[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"⌋\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\text{action\\\\_token} = \\\\lfloor a \\\\rfloor\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1.0044em\",\"verticalAlign\":\"-0.31em\"}}],[\"$\",\"span\",null,{\"className\":\"mord text\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"action_token\"}]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"⌊\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"a\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\"⌋\"}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"18:[\"$\",\"p\",null,{\"children\":[\"Depending on the architecture, these 255 (or so) action tokens might be usable as-is, or (as a hack if available tokens are limited) might overwrite the 255 \",[\"$\",\"em\",null,{\"children\":\"least used\"}],\" tokens in the upstream language model.\"]}]\n19:[\"$\",\"p\",null,{\"children\":[\"There is some nuance in how binning is applied. \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2212.06817\",\"children\":\"RT-1\"}],\"’s action tokenizer discretized uniformly across the entire action space (based on minimum and maximum values seen in the data) into 256 equal-size bins. This choice was, apparently, good enough: in the corresponding ablation study, they note a -25% success rate delta when this action tokenizer is removed (though no comparison was given with other action tokenization schemes). A near-identical scheme was reused for \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2307.15818\",\"children\":\"RT-2\"}],\" in 2023.\"]}]\n1a:[\"$\",\"p\",null,{\"children\":[\"In later 2023, Waymo's \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/pdf/2309.16534\",\"children\":\"MotionLM\"}],\" introduced some slight modifications, using a \\\"Verlet wrapper\\\" around uniformly binned deltas for each coordinate. In practice, this resulted in a substantial reduction in the number of distinct tokens required, though it was not fully specified how this reduction arose. Later, during work on \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/pdf/2406.09246\",\"children\":\"OpenVLA\"}],\" in early 2024, it was noticed that computing bins based on the minimum and maximum actuator values was vulnerable to outliers - though bins were of equal numerical size, the majority of data fell in a subset of bins, so some precision was wasted. To amend this issue, the authors of OpenVLA opted to use a quantile-based approach instead, such that each bin covered the same amount of training data:\"]}]\n"])</script><script>self.__next_f.push([1,"1b:[\"$\",\"span\",null,{\"className\":\"katex-display\",\"children\":[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mtext\",null,{\"children\":\"action_token\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"⌊\"}],[\"$\",\"mtext\",null,{\"children\":\"quantile\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"⋅\"}],[\"$\",\"mn\",null,{\"children\":\"255\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"⌋\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\text{action\\\\_token} = \\\\lfloor \\\\text{quantile}(a) \\\\cdot 255 \\\\rfloor\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1.0044em\",\"verticalAlign\":\"-0.31em\"}}],[\"$\",\"span\",null,{\"className\":\"mord text\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"action_token\"}]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"⌊\"}],[\"$\",\"span\",null,{\"className\":\"mord text\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"quantile\"}]}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"a\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mbin\",\"children\":\"⋅\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"255\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\"⌋\"}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"1c:[\"$\",\"p\",null,{\"children\":[\"Why did these simple action tokenizers survive for so long, when tokenizers in other components of the VLA stack were more complex? While it's hard to say for certain, we suspect that it was discovered early that performance does not necessarily correlate well with scale in action tokenizers. Binning is good enough in many cases, and choosing a more complex action tokenizer can impact inference times (see \",[\"$\",\"a\",null,{\"href\":\"#high-frequency-performance\",\"children\":\"high-frequency performance\"}],\").\"]}]\n1d:[\"$\",\"p\",null,{\"children\":[\"However, it was long suspected that poor action tokenization prevented dexterous performance in RT-2. Indeed, in 2025, Physical Intelligence released a performance comparison of a \\\"naive\\\" (binning) tokenizer with a new, bespoke alternative (\",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2501.09747\",\"children\":\"FAST\"}],\"), suggesting serious deterioration of performance specifically with increased sampling rate:\"]}]\n1e:[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"src\":\"https://hackmd.io/_uploads/B1OfcT0HZe.png\",\"alt\":\"Performance comparison of naive tokenizer vs FAST\"}]}]\n1f:[\"$\",\"p\",null,{\"children\":\"As such, recent trends seem to lean away from binning tokenizers - although their simplicity remains compelling.\"}]\n20:[\"$\",\"hr\",null,{}]\n21:[\"$\",\"h2\",null,{\"children\":\"The protagonist: Vector quantization and VQ-BeT\"}]\n22:[\"$\",\"p\",null,{\"children\":[\"The qualitative shift away from binning-based action tokenizers was a long time coming. By mid-2024, there was work in avoiding binning by instead learning a vector-quantized latent action space and using it as a load-bearing interface for sequence modeling, described as \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2403.03181\",\"children\":\"VQ-BeT\"}],\".\"]}]\n23:[\"$\",\"p\",null,{\"children\":\"In this audit, we use VQ-BeT as a particularly interesting case study - not for its optimality (though it performs well in several respects), but because it crystallizes the core design assumptions behind latent action quantization in VLA systems.\"}]\n24:[\"$\",\"h3\",null,{\"children\":\"How it works\"}]\n25:[\"$\",\"p\",null,{\"children\":\"VQ-BeT decomposes action generation into two explicitly separated stages: (i) offline action tokenization via residual vector quantization, and (ii) online autoregressive prediction of discrete latent codes conditioned on observations (and optionally goals). This separation reflects a deliberate reorganization of the control stack, in which representation learning, sequence modeling, and continuous execution are assigned distinct roles.\"}]\n26:[\"$\",\"h4\",null,{\"children\":\"Stage 1: Chunk tokenization via residual VQ-VAE\"}]\n"])</script><script>self.__next_f.push([1,"27:[\"$\",\"p\",null,{\"children\":[\"Given a continuous action (or short action chunk) \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\":\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}]]}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"a_{t:t+n}\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.6389em\",\"verticalAlign\":\"-0.2083em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"a\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2806em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}],[\"$\",\"span\",null,{\"className\":\"mrel mtight\",\"children\":\":\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}],[\"$\",\"span\",null,{\"className\":\"mbin mtight\",\"children\":\"+\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"n\"}]]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2083em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]]}]}]]}],\", VQ-BeT first maps it into a latent embedding using an encoder:\"]}]\n"])</script><script>self.__next_f.push([1,"28:[\"$\",\"span\",null,{\"className\":\"katex-display\",\"children\":[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"ϕ\"}],[\"$\",\"mo\",null,{\"children\":\":\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mi\",null,{\"children\":\"ϕ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\":\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}]]}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\".\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\phi: x=\\\\phi(a_{t:t+n}).\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.8889em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"ϕ\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\":\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"ϕ\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"a\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2806em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}],[\"$\",\"span\",null,{\"className\":\"mrel mtight\",\"children\":\":\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}],[\"$\",\"span\",null,{\"className\":\"mbin mtight\",\"children\":\"+\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"n\"}]]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2083em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\".\"}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"29:[\"$\",\"p\",null,{\"children\":[\"This latent is discretized using \",[\"$\",\"strong\",null,{\"children\":\"Residual Vector Quantization (RVQ)\"}],\" (\",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2107.03312\",\"children\":\"RVQ\"}],\"), where multiple vector quantizers are applied sequentially. Each quantization layer selects the nearest codebook vector to the remaining residual:\"]}]\n"])</script><script>self.__next_f.push([1,"2a:[\"$\",\"span\",null,{\"className\":\"katex-display\",\"children\":[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"z\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"munderover\",null,{\"children\":[[\"$\",\"mo\",null,{\"children\":\"∑\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"i\"}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"N\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}]]}]]}],[\"$\",\"msubsup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"z\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"i\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"z_q(x) = \\\\sum_{i=1}^{N_q} z_q^{(i)},\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1.0361em\",\"verticalAlign\":\"-0.2861em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.04398em\"},\"children\":\"z\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.1514em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.044em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2861em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"3.2143em\",\"verticalAlign\":\"-1.2777em\"}}],[\"$\",\"span\",null,{\"className\":\"mop op-limits\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"1.9367em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-1.8723em\",\"marginLeft\":\"0em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3.05em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"i\"}],[\"$\",\"span\",null,{\"className\":\"mrel mtight\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"1\"}]]}]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3.05em\"}}],[\"$\",\"span\",null,{\"children\":[\"$\",\"span\",null,{\"className\":\"mop op-symbol large-op\",\"children\":\"∑\"}]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-4.4083em\",\"marginLeft\":\"0em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3.05em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.10903em\"},\"children\":\"N\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.1645em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.357em\",\"marginLeft\":\"-0.109em\",\"marginRight\":\"0.0714em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.5em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size3 size1 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":\"$L85\"}]]}]}]]}]}]}]]}]]}],\"$L86\"]}],\"$L87\"]}]}],\"$L88\",\"$L89\",\"$L8a\"]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"2b:[\"$\",\"p\",null,{\"children\":\"and\"}]\n"])</script><script>self.__next_f.push([1,"2c:[\"$\",\"span\",null,{\"className\":\"katex-display\",\"children\":[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msubsup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"z\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"i\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]]}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mi\",null,{\"children\":\"arg\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}],[\"$\",\"munder\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"min\"}],[\"$\",\"mo\",null,{\"children\":\"⁡\"}]]}],[\"$\",\"msubsup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"e\"}],[\"$\",\"mi\",null,{\"children\":\"j\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"i\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]]}]]}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"fence\":\"true\",\"children\":\"∥\"}],[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"r\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"i\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]]}],[\"$\",\"mo\",null,{\"children\":\"−\"}],[\"$\",\"msubsup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"e\"}],[\"$\",\"mi\",null,{\"children\":\"j\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"i\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]]}],[\"$\",\"mo\",null,{\"fence\":\"true\",\"children\":\"∥\"}]]}],[\"$\",\"mn\",null,{\"children\":\"2\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"z_q^{(i)} = \\\\arg\\\\min_{e_j^{(i)}} \\\\left\\\\| r^{(i)} - e_j^{(i)} \\\\right\\\\|_2,\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1.3211em\",\"verticalAlign\":\"-0.3831em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.04398em\"},\"children\":\"z\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.938em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.453em\",\"marginLeft\":\"-0.044em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.113em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mopen mtight\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"i\"}],[\"$\",\"span\",null,{\"className\":\"mclose mtight\",\"children\":\")\"}]]}]}]]}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3831em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"2.4802em\",\"verticalAlign\":\"-1.3302em\"}}],[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":[\"ar\",[\"$\",\"span\",null,{\"style\":{\"marginRight\":\"0.01389em\"},\"children\":\"g\"}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mop op-limits\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.6679em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.0926em\",\"marginLeft\":\"0em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"e\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"1.0591em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.2134em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.0714em\"},\"children\":[\"$L8b\",\"$L8c\"]}],\"$L8d\"]}],\"$L8e\"]}],\"$L8f\"]}]}]]}]}]}]]}],\"$L90\"]}],\"$L91\"]}],\"$L92\"]}]}],\"$L93\",\"$L94\",\"$L95\",\"$L96\"]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"2d:[\"$\",\"p\",null,{\"children\":[\"where \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"r\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"i\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"r^{(i)}\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.888em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.02778em\"},\"children\":\"r\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.888em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.063em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mopen mtight\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"i\"}],[\"$\",\"span\",null,{\"className\":\"mclose mtight\",\"children\":\")\"}]]}]}]]}]}]}]}]}]]}]]}]}]]}],\" denotes the residual after subtracting the codebook vectors selected by previous layers.\"]}]\n"])</script><script>self.__next_f.push([1,"2e:[\"$\",\"p\",null,{\"children\":\"The quantized latent is then decoded back into a continuous action via a decoder:\"}]\n"])</script><script>self.__next_f.push([1,"2f:[\"$\",\"span\",null,{\"className\":\"katex-display\",\"children\":[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"ψ\"}],[\"$\",\"mo\",null,{\"children\":\":\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\":\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}]]}]]}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mi\",null,{\"children\":\"ψ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"z\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\".\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\psi:\\\\hat{a}_{t:t+n} = \\\\psi(z_q(x)).\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.8889em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"ψ\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\":\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.9028em\",\"verticalAlign\":\"-0.2083em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord accent\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.6944em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-3em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"a\"}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"accent-body\",\"style\":{\"left\":\"-0.25em\"},\"children\":[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"^\"}]}]]}]]}]}]}]}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2806em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}],[\"$\",\"span\",null,{\"className\":\"mrel mtight\",\"children\":\":\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}],[\"$\",\"span\",null,{\"className\":\"mbin mtight\",\"children\":\"+\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"n\"}]]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2083em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1.0361em\",\"verticalAlign\":\"-0.2861em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"ψ\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.04398em\"},\"children\":\"z\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.1514em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.044em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2861em\"},\"children\":\"$L97\"}]}]]}]}]]}],\"$L98\",\"$L99\",\"$L9a\",\"$L9b\"]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"30:[\"$\",\"p\",null,{\"children\":[\"VQ-BeT uses a small number of residual quantization layers (typically two), interpreting the first as capturing coarse action modes (\",[\"$\",\"em\",null,{\"children\":\"primary codes\"}],\") and subsequent layers as encoding finer-grained residual structure (\",[\"$\",\"em\",null,{\"children\":\"secondary codes\"}],\").\"]}]\n31:[\"$\",\"h4\",null,{\"children\":\"Stage 2: Autoregressive prediction of latent action codes\"}]\n32:[\"$\",\"p\",null,{\"children\":\"After training the tokenizer, it is frozen and used to convert actions into discrete codes. A GPT-style transformer is then trained to predict these codes conditioned on recent observations:\"}]\n"])</script><script>self.__next_f.push([1,"33:[\"$\",\"span\",null,{\"className\":\"katex-display\",\"children\":[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"p\"}],[\"$\",\"mo\",null,{\"fence\":\"false\",\"stretchy\":\"true\",\"minsize\":\"1.2em\",\"maxsize\":\"1.2em\",\"children\":\"(\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"{\"}],[\"$\",\"msubsup\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"z\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"i\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"}\"}],[\"$\",\"mo\",null,{\"children\":\"∣\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"o\"}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"−\"}],[\"$\",\"mi\",null,{\"children\":\"h\"}],[\"$\",\"mo\",null,{\"children\":\":\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mi\",null,{\"children\":\"g\"}],[\"$\",\"mo\",null,{\"fence\":\"false\",\"stretchy\":\"true\",\"minsize\":\"1.2em\",\"maxsize\":\"1.2em\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"p\\\\big(\\\\{z_q^{(i)}\\\\} \\\\mid o_{t-h:t}, g \\\\big),\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1.3211em\",\"verticalAlign\":\"-0.3831em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"p\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[\"$\",\"span\",null,{\"className\":\"delimsizing size1\",\"children\":\"(\"}]}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"{\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.04398em\"},\"children\":\"z\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.938em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.453em\",\"marginLeft\":\"-0.044em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.113em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mopen mtight\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"i\"}],[\"$\",\"span\",null,{\"className\":\"mclose mtight\",\"children\":\")\"}]]}]}]]}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3831em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\"}\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"∣\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1.2em\",\"verticalAlign\":\"-0.35em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"o\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3361em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}],[\"$\",\"span\",null,{\"className\":\"mbin mtight\",\"children\":\"−\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"h\"}],[\"$\",\"span\",null,{\"className\":\"mrel mtight\",\"children\":\":\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}]]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2083em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"g\"}],\"$L9c\",\"$L9d\"]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"34:[\"$\",\"p\",null,{\"children\":[\"where \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"g\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"g\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"g\"}]]}]}]]}],\" is an optional goal signal.\"]}]\n35:[\"$\",\"p\",null,{\"children\":\"Rather than predicting a single token per timestep, the model predicts one categorical distribution per quantization layer. Training loss weights errors in primary code prediction more heavily than secondary codes, reflecting the intended coarse-to-fine structure of the latent space.\"}]\n36:[\"$\",\"h4\",null,{\"children\":\"Stage 3: Offset head and continuous correction\"}]\n37:[\"$\",\"p\",null,{\"children\":[\"To compensate for the loss of precision introduced by discretization, VQ-BeT adds a continuous \",[\"$\",\"strong\",null,{\"children\":\"offset head\"}],\" that predicts a residual correction to the decoded action:\"]}]\n"])</script><script>self.__next_f.push([1,"38:[\"$\",\"span\",null,{\"className\":\"katex-display\",\"children\":[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mover\",null,{\"accent\":\"true\",\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"children\":\"^\"}]]}],[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\":\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"mi\",null,{\"children\":\"n\"}]]}]]}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mi\",null,{\"children\":\"ψ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"z\"}],[\"$\",\"mi\",null,{\"children\":\"q\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"x\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"+\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"ζ\"}],[\"$\",\"mtext\",null,{\"children\":\"offset\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"o\"}],[\"$\",\"mi\",null,{\"children\":\"t\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mi\",null,{\"mathvariant\":\"normal\",\"children\":\".\"}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\hat{a}_{t:t+n} = \\\\psi(z_q(x)) + \\\\zeta_{\\\\text{offset}}(o_t).\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.9028em\",\"verticalAlign\":\"-0.2083em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord accent\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.6944em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-3em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"a\"}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"accent-body\",\"style\":{\"left\":\"-0.25em\"},\"children\":[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"^\"}]}]]}]]}]}]}]}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2806em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}],[\"$\",\"span\",null,{\"className\":\"mrel mtight\",\"children\":\":\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}],[\"$\",\"span\",null,{\"className\":\"mbin mtight\",\"children\":\"+\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"n\"}]]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2083em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}]]}],[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1.0361em\",\"verticalAlign\":\"-0.2861em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"ψ\"}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.04398em\"},\"children\":\"z\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.1514em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.044em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2861em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}],\"$L9e\",\"$L9f\",\"$La0\",\"$La1\"]}],\"$La2\"]}]]}]}]\n"])</script><script>self.__next_f.push([1,"39:[\"$\",\"p\",null,{\"children\":\"This offset is trained with a regression loss and applied at execution time, providing a mechanism for fine-grained adjustment while preserving a discrete decision interface.\"}]\n3a:[\"$\",\"hr\",null,{}]\n3b:[\"$\",\"p\",null,{\"children\":\"Taken together, VQ-BeT does not eliminate continuous control, but redistributes it. Discrete latent codes are used to model long-horizon structure and multimodality, while continuous correction is relegated to the decoder and offset pathways. This division of responsibility is central to both the strengths and limitations of vector-quantized action tokenization.\"}]\n3c:[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"src\":\"https://hackmd.io/_uploads/BJfrvNk8Wx.png\",\"alt\":\"VQ-BeT overview\"}]}]\n3d:[\"$\",\"h3\",null,{\"children\":\"Other vector quantization approaches\"}]\n3e:[\"$\",\"p\",null,{\"children\":[\"Vector quantization has appeared in a range of neighboring contexts, from representation compression to skill abstraction, with substantially different system-level roles. In most prior uses—such as \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/1711.00937\",\"children\":\"VQ-VAE\"}],\"-style compression or skill-centric methods like \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2407.15840\",\"children\":\"QueST\"}],\" —quantized latents serve either efficiency or reuse, rather than acting as a direct interface to token-based sequence models.\"]}]\n3f:[\"$\",\"p\",null,{\"children\":[\"VQ-BeT distinguishes itself by adopting vector quantization explicitly as an action tokenization mechanism for autoregressive modeling, positioning discrete latent actions as the primary interface between continuous control and sequence prediction. More recent work, such as \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2507.01016\",\"children\":\"VQ-VLA\"}],\", extends this design by scaling the tokenizer itself, but preserves the same core abstraction introduced by VQ-BeT: discrete latent actions as the primary interface to sequence models.\"]}]\n40:[\"$\",\"p\",null,{\"children\":\"This framing allows us to treat VQ-BeT as a representative instance of latent action tokenization, and motivates a broader comparative evaluation of action tokenization strategies at the system level.\"}]\n41:[\"$\",\"h3\",null,{\"children\":\"Preliminary evaluations\"}]\n42:[\"$\",\"p\",null,{\"children\":\"At a high level, VQ-BeT demonstrates that vector-quantized action representations can support a wide range of behaviors across simulated and real-world robotic tasks. Empirically, the model shows improved multimodal behavior generation and long-horizon stability compared to simple discretization baselines, particularly in offline imitation settings.\"}]\n43:[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"src\":\"https://hackmd.io/_uploads/Sk2snE1Ibe.png\",\"alt\":\"VQ-BeT results figure\"}]}]\n44:[\"$\",\"p\",null,{\"children\":\"However, these evaluations are necessarily entangled with other design choices, including backbone architecture, observation encoding, training data composition, and execution-time control strategies. As a result, reported performance gains cannot be attributed to action tokenization in isolation.\"}]\n45:[\"$\",\"p\",null,{\"children\":[\"Rather than treating these results as definitive evidence for or against vector-quantized action tokenization, we view them as establishing \",[\"$\",\"em\",null,{\"children\":\"plausibility\"}],\": VQ-BeT demonstrates that learned discrete latent actions are a viable interface for sequence models in robotics. The more consequential questions—regarding scalability, robustness, control fidelity, and engineering complexity—require evaluation at the system level.\"]}]\n46:[\"$\",\"hr\",null,{}]\n47:[\"$\",\"h2\",null,{\"children\":\"The cutting edge: New action tokenizers\"}]\n48:[\"$\",\"p\",null,{\"children\":\"Before stepping into that evaluation, we'll first note some very recent developments in the area outside VQ-BeT.\"}]\n49:[\"$\",\"h3\",null,{\"children\":\"Frequency-space action tokenization\"}]\n4a:[\"$\",\"p\",null,{\"children\":[\"Earlier, we showed a comparison between a binning tokenizer and a modern \\\"bespoke\\\" tokenizer. That bespoke tokenizer was \",[\"$\",\"em\",null,{\""])</script><script>self.__next_f.push([1,"children\":\"frequency-space action sequence tokenization\"}],\" (\",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/pdf/2501.09747\",\"children\":\"FAST\"}],\"), released in early 2025. FAST is based on the \",[\"$\",\"a\",null,{\"href\":\"https://en.wikipedia.org/wiki/Discrete_cosine_transform#Formal_definition\",\"children\":\"discrete cosine transform\"}],\" (DCT), a widely used concept in signal processing (e.g. in JPEG compression; see also \",[\"$\",\"a\",null,{\"href\":\"https://ieeexplore.ieee.org/document/125072\",\"children\":\"IEEE paper\"}],\"). In short, FAST applies the DCT to normalized actions, bins the DCT coefficients, and applies byte-pair encoding:\"]}]\n"])</script><script>self.__next_f.push([1,"4b:[\"$\",\"span\",null,{\"className\":\"katex-display\",\"children\":[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"display\":\"block\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mtable\",null,{\"rowspacing\":\"0.25em\",\"columnalign\":\"right left\",\"columnspacing\":\"0em\",\"children\":[[\"$\",\"mtr\",null,{\"children\":[[\"$\",\"mtd\",null,{\"children\":[\"$\",\"mstyle\",null,{\"scriptlevel\":\"0\",\"displaystyle\":\"true\",\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mtext\",null,{\"children\":\"norm\"}]]}]}]}],[\"$\",\"mtd\",null,{\"children\":[\"$\",\"mstyle\",null,{\"scriptlevel\":\"0\",\"displaystyle\":\"true\",\"children\":[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mrow\",null,{}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mn\",null,{\"children\":\"2\"}],[\"$\",\"mo\",null,{\"children\":\"⋅\"}],[\"$\",\"mtext\",null,{\"children\":\"quantile\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}],[\"$\",\"mo\",null,{\"children\":\"−\"}],[\"$\",\"mn\",null,{\"children\":\"1\"}]]}]}]}]]}],[\"$\",\"mtr\",null,{\"children\":[[\"$\",\"mtd\",null,{\"children\":[\"$\",\"mstyle\",null,{\"scriptlevel\":\"0\",\"displaystyle\":\"true\",\"children\":[\"$\",\"mi\",null,{\"children\":\"M\"}]}]}],[\"$\",\"mtd\",null,{\"children\":[\"$\",\"mstyle\",null,{\"scriptlevel\":\"0\",\"displaystyle\":\"true\",\"children\":[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mrow\",null,{}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mtext\",null,{\"children\":\"DCT\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"a\"}],[\"$\",\"mtext\",null,{\"children\":\"norm\"}]]}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]}]}]]}],[\"$\",\"mtr\",null,{\"children\":[[\"$\",\"mtd\",null,{\"children\":[\"$\",\"mstyle\",null,{\"scriptlevel\":\"0\",\"displaystyle\":\"true\",\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"M\"}],[\"$\",\"mtext\",null,{\"children\":\"bin\"}]]}]}]}],[\"$\",\"mtd\",null,{\"children\":[\"$\",\"mstyle\",null,{\"scriptlevel\":\"0\",\"displaystyle\":\"true\",\"children\":[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mrow\",null,{}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"⌊\"}],[\"$\",\"mi\",null,{\"children\":\"γ\"}],[\"$\",\"mi\",null,{\"children\":\"M\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"⌋\"}]]}]}]}]]}],[\"$\",\"mtr\",null,{\"children\":[[\"$\",\"mtd\",null,{\"children\":[\"$\",\"mstyle\",null,{\"scriptlevel\":\"0\",\"displaystyle\":\"true\",\"children\":[\"$\",\"mtext\",null,{\"children\":\"action_tokens\"}]}]}],[\"$\",\"mtd\",null,{\"children\":[\"$\",\"mstyle\",null,{\"scriptlevel\":\"0\",\"displaystyle\":\"true\",\"children\":[\"$\",\"mrow\",null,{\"children\":[[\"$\",\"mrow\",null,{}],[\"$\",\"mo\",null,{\"children\":\"=\"}],[\"$\",\"mtext\",null,{\"children\":\"BPE\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\"(\"}],[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"M\"}],[\"$\",\"mtext\",null,{\"children\":\"bin\"}]]}],[\"$\",\"mo\",null,{\"separator\":\"true\",\"children\":\",\"}],[\"$\",\"mi\",null,{\"children\":\"ϕ\"}],[\"$\",\"mo\",null,{\"stretchy\":\"false\",\"children\":\")\"}]]}]}]}]]}]]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\begin{aligned}\\na_{\\\\text{norm}} \u0026= 2 \\\\cdot \\\\text{quantile}(a) - 1 \\\\\\\\\\nM \u0026= \\\\text{DCT}(a_{\\\\text{norm}}) \\\\\\\\\\nM_{\\\\text{bin}} \u0026= \\\\lfloor \\\\gamma M \\\\rfloor \\\\\\\\\\n\\\\text{action\\\\_tokens} \u0026= \\\\text{BPE}(M_{\\\\text{bin}}, \\\\phi)\\n\\\\end{aligned}\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"6em\",\"verticalAlign\":\"-2.75em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[\"$\",\"span\",null,{\"className\":\"mtable\",\"children\":[[\"$\",\"span\",null,{\"className\":\"col-align-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"3.25em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-5.41em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"a\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.1514em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord text mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"norm\"}]}]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.91em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.10903em\"},\"children\":\"M\"}]}]]}],\"$La3\",\"$La4\"]}],\"$La5\"]}],\"$La6\"]}]}],\"$La7\"]}]}]]}]}]]}]}]\n"])</script><script>self.__next_f.push([1,"4c:[\"$\",\"p\",null,{\"children\":[\"$\",\"img\",null,{\"src\":\"https://hackmd.io/_uploads/HkobvekU-g.png\",\"alt\":\"FAST diagram\"}]}]\n"])</script><script>self.__next_f.push([1,"4d:[\"$\",\"p\",null,{\"children\":[\"There are two parameters here: \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"γ\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\gamma\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.625em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.05556em\"},\"children\":\"γ\"}]]}]}]]}],\", which controls the resolution of the bins for the DCT coefficients, and \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"ϕ\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\phi\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.8889em\",\"verticalAlign\":\"-0.1944em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"ϕ\"}]]}]}]]}],\", the BPE codebook, which must be learned. \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"mi\",null,{\"children\":\"a\"}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"a\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.4306em\"}}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"a\"}]]}]}]]}],\", here, is generally an action chunk rather than a single action.\"]}]\n"])</script><script>self.__next_f.push([1,"4e:[\"$\",\"p\",null,{\"children\":[\"FAST is a learned tokenizer. The same paper also provides FAST+, an ostensibly universal pretraining of FAST on a wide variety of robot morphologies. VQ-BeT, already discussed, is learned as well. But it remains an open question whether training action tokenizers is always practical or convenient, and work continues on non-trained tokenizers. Late 2025 also saw the release of \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/pdf/2506.06072\",\"children\":\"BEAST\"}],\", a no-learning, B-spline-based action tokenizer.\"]}]\n4f:[\"$\",\"h3\",null,{\"children\":\"Actions in continuous space\"}]\n50:[\"$\",\"p\",null,{\"children\":\"Can we avoid having to use discrete actions entirely?\"}]\n"])</script><script>self.__next_f.push([1,"51:[\"$\",\"p\",null,{\"children\":[\"This remains an open question. In late 2024, there was some significant work (\",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/2409.12514\",\"children\":\"arXiv:2409.12514\"}],\") involving the usage of diffusion models to avoid tokenizing actions at all. The approach, taken as part of an optimized fine-tuning regime, also yielded a success rate increase in \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/pdf/2502.19645\",\"children\":\"OpenVLA-OFT\"}],\". Initially, \",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/html/2410.24164v1\",\"children\":[\"the \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"π\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi_0\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.5806em\",\"verticalAlign\":\"-0.15em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.0359em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"0\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]]}]}]]}],\" model used a similar approach\"]}],\"... but is outperformed in some respects by \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"π\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi_0\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.5806em\",\"verticalAlign\":\"-0.15em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.0359em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"0\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]]}]}]]}],\"-FAST, which uses the FAST action tokenizer.\"]}]\n"])</script><script>self.__next_f.push([1,"52:[\"$\",\"p\",null,{\"children\":\"We won't go into the details of these methods in this audit, but we will provide some general analysis of the pragmatism of using such methods in comparison to traditional action tokenization.\"}]\n53:[\"$\",\"hr\",null,{}]\n54:[\"$\",\"a\",null,{\"id\":\"evaluating-action-tokenizers\"}]\n55:[\"$\",\"h1\",null,{\"children\":\"[4] Evaluating action tokenizers\"}]\n56:[\"$\",\"p\",null,{\"children\":[\"Our evaluation covers three major contexts: action tokenizers as \",[\"$\",\"em\",null,{\"children\":\"scalable components\"}],\", as \",[\"$\",\"em\",null,{\"children\":\"real-world systems\"}],\", and as \",[\"$\",\"em\",null,{\"children\":\"engineered mechanisms\"}],\", focusing respectively on the difficulties of scaling, running, and developing models based on these action tokenizers.\"]}]\n57:[\"$\",\"p\",null,{\"children\":\"Unfortunately, action tokenizers are not conveniently separated from other components of VLA models - often they are bundled with other iterative improvements. As such, it's misleading to provide strict quantitative comparisons based solely on publicly available data. In a few places, we use a rough ranking system to provide our first-principles expectations, based on the color-coded system sometimes seen in hardware reviews: 🔵 denotes \\\"best in class,\\\" 🟢 \\\"good,\\\" 🟡 \\\"situational\\\" or \\\"outdated,\\\" and 🔴 \\\"best avoided.\\\"\"}]\n58:[\"$\",\"p\",null,{\"children\":\"Our contenders are as follows:\"}]\n"])</script><script>self.__next_f.push([1,"59:[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"Type\"}],[\"$\",\"th\",null,{\"children\":\"Action tokenization approach\"}],[\"$\",\"th\",null,{\"children\":\"Representative\"}],[\"$\",\"th\",null,{\"children\":\"Release\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Binning\"}],[\"$\",\"td\",null,{\"children\":\"Naive binning\"}],[\"$\",\"td\",null,{\"children\":\"RT-2\"}],[\"$\",\"td\",null,{\"children\":\"2023\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Binning\"}],[\"$\",\"td\",null,{\"children\":\"Quantile binning\"}],[\"$\",\"td\",null,{\"children\":\"OpenVLA\"}],[\"$\",\"td\",null,{\"children\":\"2024\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"VQ\"}],[\"$\",\"td\",null,{\"children\":\"Residual VQ-VAE\"}],[\"$\",\"td\",null,{\"children\":\"VQ-BeT\"}],[\"$\",\"td\",null,{\"children\":\"2024\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"DCT\"}],[\"$\",\"td\",null,{\"children\":\"FAST\"}],[\"$\",\"td\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"π\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi_0\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.5806em\",\"verticalAlign\":\"-0.15em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.0359em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"0\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]]}]}]]}],\"-FAST\"]}],[\"$\",\"td\",null,{\"children\":\"2025\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"None\"}],[\"$\",\"td\",null,{\"children\":\"Diffusion / flow matching\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"π\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi_0\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.5806em\",\"verticalAlign\":\"-0.15em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.0359em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"0\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]]}]}]]}]}],[\"$\",\"td\",null,{\"children\":\"2024\"}]]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"5a:[\"$\",\"hr\",null,{}]\n5b:[\"$\",\"h2\",null,{\"children\":\"As real-world systems\"}]\n5c:[\"$\",\"p\",null,{\"children\":\"From the perspective of technical auditing, we first focus on the role of action tokenization in the deployment of the system in the real world. When deployed on physical robots, action tokenizers define more than a representational interface—they define how control authority, feedback, and error correction are distributed across the VLA stack. Discretizing actions necessarily introduces delay, abstraction, or loss of metric structure, and different tokenization strategies make fundamentally different assumptions about when and where these costs can be absorbed.\"}]\n5d:[\"$\",\"p\",null,{\"children\":\"In this section, we audit action tokenizers under real-world constraints such as latency, high-frequency control, contact dynamics, and partial observability. Rather than asking whether a tokenizer can generate plausible actions, we ask where precise control is enforced, how feedback is incorporated, and which failures are structurally invisible to the model’s decision-making process. These questions determine whether a tokenization strategy remains viable outside scripted evaluation settings.\"}]\n5e:[\"$\",\"h3\",null,{\"children\":\"Architectural lock-in and control philosophy\"}]\n5f:[\"$\",\"p\",null,{\"children\":\"Action tokenization fixes architectural commitments before learning begins: it determines where control authority, precision, and feedback are expected to reside in the VLA stack, and constrains which modeling paradigms are viable downstream.\"}]\n60:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Primitive discretization\"}],\" places control precision directly on the sequence model.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Latent action tokenization\"}],\" shifts it to decoders and execution-time correction.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Continuous-action approaches\"}],\" retain it within the policy itself.\"]}],\"\\n\"]}]\n61:[\"$\",\"p\",null,{\"children\":\"These choices are not interchangeable. Each commits the system to a different distribution of responsibility, shaping which errors can be corrected downstream and which failures are structural rather than incidental.\"}]\n62:[\"$\",\"a\",null,{\"id\":\"high-frequency-performance\"}]\n63:[\"$\",\"h3\",null,{\"children\":\"High-frequency performance\"}]\n64:[\"$\",\"p\",null,{\"children\":\"High-frequency control exposes where tokenization delays or abstracts feedback. Discrete action tokens necessarily operate at a coarser temporal granularity than physical dynamics, forcing systems to assume that short-horizon correction can be deferred or handled outside the tokenized decision loop.\"}]\n65:[\"$\",\"p\",null,{\"children\":\"Under these conditions, different tokenization strategies fail differently. Primitive discretization degrades precision as update rates increase; latent action tokenization relies on decoders or offset pathways to absorb rapid corrections; continuous-action approaches retain immediate feedback at the cost of heavier computation and tighter coupling. Performance at high frequency therefore reflects not model capacity, but whether the tokenization boundary aligns with the timescale at which control errors must be corrected.\"}]\n"])</script><script>self.__next_f.push([1,"66:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"🔵 \",[\"$\",\"strong\",null,{\"children\":\"DCT (FAST):\"}],\" FAST \",[\"$\",\"em\",null,{\"children\":\"should\"}],\" be the clear candidate for \\\"best in class,\\\" given that it's designed for high-frequency scenarios. And indeed, \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"π\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi_0\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.5806em\",\"verticalAlign\":\"-0.15em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.0359em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"0\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]]}]}]]}],\"-FAST quantitatively outperforms OpenVLA-style binning at high frequencies, but not because FAST is faster at inference. The idea is that action chunks are heavily temporally correlated, which diminishes the effectiveness of the next-token prediction objective (which might lead to simply repeating the tokens). But \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"π\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi_0\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.5806em\",\"verticalAlign\":\"-0.15em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.0359em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"0\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]]}]}]]}],\"-FAST is actually \",[\"$\",\"em\",null,{\"children\":\"slower\"}],\" at inference than \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"π\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi_0\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.5806em\",\"verticalAlign\":\"-0.15em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":\"$La8\"}],\"$La9\"]}],\"$Laa\"]}]}]]}]]}]}]]}],\"—apparently due to an overreliance on autoregressive decoding. We ultimately chose to award it the \\\"best in class\\\" anyway based on recent work from Physical Intelligence working around that issue (\",\"$Lab\",\").\"]}],\"\\n\",\"$Lac\",\"\\n\",\"$Lad\",\"\\n\",\"$Lae\",\"\\n\",\"$Laf\",\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"67:[\"$\",\"h3\",null,{\"children\":\"Semantic-motor gaps and error attribution\"}]\n68:[\"$\",\"p\",null,{\"children\":\"Action tokenization mediates the mapping from semantic intent to motor execution, creating a gap in which high-level decisions may be correct while physical outcomes are not. This gap is unavoidable in VLA systems, but different tokenization strategies assign responsibility for resolving it to different components of the stack.\"}]\n69:[\"$\",\"p\",null,{\"children\":\"With primitive discretization, the sequence model must implicitly learn motor semantics it is poorly suited to represent. Latent action tokenization shifts this burden to decoders and execution-time correction, assuming that semantic errors can be compensated downstream. Continuous-action approaches keep semantic and motor variables coupled, reducing abstraction but preserving accountability. The key distinction is not whether misalignment occurs, but where the system expects it to be resolved—and which component is blamed when it is not.\"}]\n6a:[\"$\",\"h3\",null,{\"children\":\"Failure modes\"}]\n6b:[\"$\",\"p\",null,{\"children\":\"Some failures introduced by action tokenization are structurally invisible to training objectives. When discretization abstracts away timing, contact, or fine-grained feedback, the resulting errors may not appear in token-level losses or imitation metrics, even though they may be obvious at execution time. The following failures are not implementation bugs, but consequences of information that never crosses the action tokenization interface.\"}]\n"])</script><script>self.__next_f.push([1,"6c:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Dexterous manipulation:\"}],\" This is the most straightforward and commonly recognized failure mode, caused when there is too little precision in the action token vocabulary to specify very precise motions.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Literal actuator awareness:\"}],\" Most of the time, natural language is substantially vaguer than motion, so action tokens are sufficient to represent most desired motions. But if a (byzantine) roboticist were to prompt, in natural language, \\\"set gripper to state 50,\\\" there is no guarantee that the instruction would be exactly executed as requested. (In fact, if the fine-tuning dataset used refers primarily to gross actions, as many do, there is no guarantee that the system would associate a \\\"gripper\\\" language token with a gripper action token at all.)\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Token conflation:\"}],\" Few papers discuss in detail how non-action tokens are masked out of the output, if they happen to be generated erroneously.\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Inversely, OpenVLA (and potentially other LLaMA-backed VLAs) apply a hack when the number of action tokens (bins) exceeds the number of available extra tokens: they overwrite the \",[\"$\",\"em\",null,{\"children\":\"least used\"}],\" language tokens. They do not specify how the upstream tokenizer is made aware of this. While minor, this choice could potentially result in action tokens being unexpectedly received as input.\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Action token stasis:\"}],\" For trained action tokenizers like VQ-VAE, it's particularly important that the training data are representative of all reasonable action chunks. Introducing a new motion may require restructuring the entire latent space.\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"6d:[\"$\",\"h3\",null,{\"children\":\"Scaling with respect to data\"}]\n6e:[\"$\",\"p\",null,{\"children\":\"From a scaling perspective, an action tokenizer should function as a reusable abstraction rather than a task-specific artifact. Scaling stresses the tokenization boundary first: as data diversity, model capacity, and deployment scope increase, weaknesses in how actions are abstracted tend to amplify rather than average out. The question is whether scaling reduces control error, or merely relocates it elsewhere in the system.\"}]\n"])</script><script>self.__next_f.push([1,"6f:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"🔵 \",[\"$\",\"strong\",null,{\"children\":\"Residual VQ:\"}],\" The performance of VQ-BeT seems to diminish only marginally with the size of the VQ codebook, according to the VQ-BeT paper, which is an exciting data-scaling result when it is the complexity of the robot data (not necessarily the amount) that is scaled. Training the tokenizer does not appear to be a terrible inconvenience. (It could potentially be done with simulated data, at least for gross quantization in the primary VQ-residual layer.)\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"🟢 \",[\"$\",\"strong\",null,{\"children\":\"DCT (FAST):\"}],\" FAST comes with a fantastic promise: that it (FAST+ specifically) can be applied as an action tokenizer for any VLA, no modifications necessary. Whether it delivers on this promise seems like an open question to us. FAST+ required a tremendous amount of robot data to train (1M trajectories across dozens of embodiments), and it's difficult to imagine acquiring even more should that prove to be insufficient for any particular morphology.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"🟡 \",[\"$\",\"strong\",null,{\"children\":[\"Diffusion (\",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"π\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi_0\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.5806em\",\"verticalAlign\":\"-0.15em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.0359em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"0\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]]}]}]]}],\"):\"]}],\" It's not possible to separately train an action tokenizer in this setup, leaving one completely at the mercy of training a flow-matching model.\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"70:[\"$\",\"p\",null,{\"children\":\"Binning is a trainingless approach, so we consider mostly the ways in which those schemes affect the data efficiency of the entire pipeline.\"}]\n71:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"🔴 \",[\"$\",\"strong\",null,{\"children\":\"Naive binning (RT-2):\"}],\" While it worked well enough at the time, RT-2's naive action tokenizer is vulnerable to outliers, effectively reducing the richness of the data used for fine-tuning. The individual-actuator tokenization also fails to exploit correlations between actuators, which is a shame, since the authors note that the robot dataset on which RT-2 is fine-tuned is insufficient to allow for acquiring new motion skills.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"🟡 \",[\"$\",\"strong\",null,{\"children\":\"Quantile binning (OpenVLA):\"}],\" An improvement on the naive approach, but still done per-actuator.\"]}],\"\\n\"]}]\n72:[\"$\",\"h3\",null,{\"children\":\"Scaling with respect to compute and parameters\"}]\n73:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"🔵 \",[\"$\",\"strong\",null,{\"children\":\"Diffusion:\"}],\" At the core interface level, action discretization is a fundamentally lossy layer. It also hides some embodiment knowledge from the robot during fine-tuning, in that only the action tokens, not the actions themselves, are legible. As such, we find a continuous-output approach to be compelling specifically in the situation where compute is plentiful (where it could otherwise be wasted at this lossy boundary).\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"🟡 \",[\"$\",\"strong\",null,{\"children\":\"Residual VQ, DCT:\"}],\" We don't see any particular distinguishing factors here.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"🔴 \",[\"$\",\"strong\",null,{\"children\":\"Binning:\"}],\" Has only trivial parameters, and no amount of compute will make better use of them. In theory, if compute resources were to far outweigh any other, a very large number of bins could be used to alleviate some issues here, but it's difficult to imagine a world where compute is so plentiful that it's not even marginally worthwhile to reduce the number of action tokens needed.\"]}],\"\\n\"]}]\n74:[\"$\",\"hr\",null,{}]\n75:[\"$\",\"h1\",null,{\"children\":\"[5] Bottom line\"}]\n76:[\"$\",\"p\",null,{\"children\":\"Our overall final word on which action tokenizer you should use depends on the context, which we hope will also illuminate the fundamental tradeoffs involved.\"}]\n77:[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"If you're aiming for small and fast:\"}],\" Start with a VQ-VAE-based method and alter as needed. It's representative and not too opaque. Don't forget action chunking.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"If you're hyperscaling / hypergeneralizing:\"}],\" Why discretize actions at all? It will only be a bottleneck to dexterity. If you really need a tokenizer and you want something suitably general, try FAST+.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"If you need \\\"good enough\\\" right now, and you don't have data to spare:\"}],\" If FAST(+) works, use that; it'll be much more effective at high frequencies and precisions. Otherwise, binning was good enough for RT-2.\"]}],\"\\n\"]}]\n78:[\"$\",\"h3\",null,{\"children\":\"Truly foundational vs marginal gain\"}]\n79:[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"We think VQ-BeT qualifies as foundational.\"}],\" In the face of FAST, BEAST, and other new action tokenizers, it might not be strictly the best, but it did mark a turning point in seriously considering how action tokenization affects VLA performance. That said, it's unclear whether VQ itself will persist as a compelling form of action tokenization, or even whether we will continue to discretize actions at all.\"]}]\n7a:[\"$\",\"h2\",null,{\"children\":\"For further discussion\"}]\n7b:[\"$\",\"p\",null,{\"children\":\"This audit is limited in its scope - you can help by commenting on it (see the repo discussion threads if available). In particular, in potential future versions, we'd like to discuss:\"}]\n7c:[\"$\",\"ul\",null,{\"chil"])</script><script>self.__next_f.push([1,"dren\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Action chunking, in its entirety.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"More details on FAST (particularly on its training).\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Further discussion on how chosen backbones affect the choice of action tokenization (if at all).\"}],\"\\n\"]}]\n7d:[\"$\",\"hr\",null,{}]\n7e:[\"$\",\"h1\",null,{\"children\":\"[6] References\"}]\n7f:[\"$\",\"h2\",null,{\"children\":\"Binning-based action tokenization\"}]\n80:[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Brohan, A., et al. (2022). \",[\"$\",\"em\",null,{\"children\":\"RT-1: Robotics Transformer for Real-World Control at Scale.\"}],\" arXiv:2212.06817.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Brohan, A., et al. (2023). \",[\"$\",\"em\",null,{\"children\":\"RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control.\"}],\" arXiv:2307.15818.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Shi, W., Zhao, H., Liu, Y., et al. (2023). \",[\"$\",\"em\",null,{\"children\":\"MotionLM: Multi-Agent Motion Forecasting as Language Modeling.\"}],\" arXiv:2309.16534.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Kim, S., Liu, M., He, T., et al. (2024). \",[\"$\",\"em\",null,{\"children\":\"OpenVLA: An Open-Source Vision-Language-Action Model.\"}],\" arXiv:2406.09246.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Kim, S., Liu, M., He, T., et al. (2025). \",[\"$\",\"em\",null,{\"children\":\"OpenVLA-OFT: Efficient Online Fine-Tuning for Vision-Language-Action Models.\"}],\" arXiv:2502.19645.\"]}],\"\\n\"]}]\n81:[\"$\",\"h2\",null,{\"children\":\"Vector-quantized latent action tokenization\"}]\n"])</script><script>self.__next_f.push([1,"82:[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Lee, S., Wang, Y., Etukuru, H., Kim, H. J., Shafiullah, N. M. M., \u0026 Pinto, L. (2024). \",[\"$\",\"em\",null,{\"children\":\"VQ-BeT: Behavior Generation with Latent Actions.\"}],\" ICML 2024 (Spotlight).\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Shafiullah, N. M. M., Pinto, L., et al. (2022). \",[\"$\",\"em\",null,{\"children\":\"BeT: Imitation Learning with Latent Actions.\"}],\" arXiv:2206.11251.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"van den Oord, A., Vinyals, O., \u0026 Kavukcuoglu, K. (2017). \",[\"$\",\"em\",null,{\"children\":\"Neural Discrete Representation Learning.\"}],\" NeurIPS 2017.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Zeghidour, N., Pueyo, A., Tagliasacchi, M., \u0026 Tagliasacchi, M. (2021). \",[\"$\",\"em\",null,{\"children\":\"SoundStream: An End-to-End Neural Audio Codec.\"}],\" IEEE/ACM TASLP (2021).\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Wang, Y., Zhu, H., Liu, M., Yang, J., Fang, H.-S., \u0026 He, T. (2025). \",[\"$\",\"em\",null,{\"children\":\"VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers.\"}],\" ICCV 2025.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Mete, S., Saxena, S., Isik, B., Geng, J., Ermon, S., \u0026 Shafiullah, N. M. M. (2024). \",[\"$\",\"em\",null,{\"children\":\"QueST: Self-Supervised Skill Abstractions for Learning Continuous Control.\"}],\" NeurIPS 2024.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Wu, J., et al. (2024). \",[\"$\",\"em\",null,{\"children\":\"MiniVLA: A Lightweight Vision-Language-Action Model.\"}],\" Stanford AI Lab Blog.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Li, Y., et al. (2024). \",[\"$\",\"em\",null,{\"children\":\"3D-VLA: 3D-Aware Vision-Language-Action Models for Robotic Manipulation.\"}],\" arXiv:2403.09631.\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"83:[\"$\",\"h2\",null,{\"children\":\"Signal-space and continuous-action alternatives\"}]\n"])</script><script>self.__next_f.push([1,"84:[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Ding, Y., Li, X., Xu, D., et al. (2025). \",[\"$\",\"em\",null,{\"children\":\"FAST: Frequency-Space Action Sequence Tokenization for Robotic Control.\"}],\" arXiv:2501.09747.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Black, K., Brown, N., Xia, F., et al. (2024). \",[\"$\",\"em\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"π\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi_0\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.5806em\",\"verticalAlign\":\"-0.15em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.0359em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"0\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]]}]}]]}],\": A Vision-Language-Action Model with Continuous Control.\"]}],\" arXiv:2410.24164.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Zhang, Y., Liu, Z., Xu, Y., et al. (2025). \",[\"$\",\"em\",null,{\"children\":\"BEAST: B-Spline Encoding for Action Sequence Tokenization.\"}],\" arXiv:2506.06072.\"]}],\"\\n\"]}]\n"])</script><script>self.__next_f.push([1,"85:[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2819em\"},\"children\":[\"$\",\"span\",null,{}]}]\n86:[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]\n87:[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"1.2777em\"},\"children\":[\"$\",\"span\",null,{}]}]}]\n88:[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}]\n"])</script><script>self.__next_f.push([1,"89:[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.04398em\"},\"children\":\"z\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.938em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.453em\",\"marginLeft\":\"-0.044em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"q\"}]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.113em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mopen mtight\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"i\"}],[\"$\",\"span\",null,{\"className\":\"mclose mtight\",\"children\":\")\"}]]}]}]]}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3831em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"8a:[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}]\n8b:[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.5357em\"}}]\n8c:[\"$\",\"span\",null,{\"className\":\"sizing reset-size3 size1 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.05724em\"},\"children\":\"j\"}]}]\n8d:[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.0591em\",\"marginRight\":\"0.0714em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.5357em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size3 size1 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mopen mtight\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"i\"}],[\"$\",\"span\",null,{\"className\":\"mclose mtight\",\"children\":\")\"}]]}]}]]}]\n8e:[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]\n8f:[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.4612em\"},\"children\":[\"$\",\"span\",null,{}]}]}]\n90:[\"$\",\"span\",null,{\"style\":{\"top\":\"-3em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"children\":[\"$\",\"span\",null,{\"className\":\"mop\",\"children\":\"min\"}]}]]}]\n91:[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]\n92:[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"1.3302em\"},\"children\":[\"$\",\"span\",null,{}]}]}]\n93:[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}]\n"])</script><script>self.__next_f.push([1,"94:[\"$\",\"span\",null,{\"className\":\"minner\",\"children\":[[\"$\",\"span\",null,{\"className\":\"minner\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":[\"$\",\"span\",null,{\"className\":\"delimsizing mult\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"1.15em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.15em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3.8em\"}}],[\"$\",\"span\",null,{\"style\":{\"width\":\"0.556em\",\"height\":\"1.800em\"},\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":\"0.556em\",\"height\":\"1.800em\",\"viewBox\":\"0 0 556 1800\",\"children\":[\"$\",\"path\",null,{\"d\":\"M145 15 v585 v600 v585 c2.667,10,9.667,15,21,15\\nc10,0,16.667,-5,20,-15 v-585 v-600 v-585 c-2.667,-10,-9.667,-15,-21,-15\\nc-10,0,-16.667,5,-20,15z M188 15 H145 v585 v600 v585 h43z\\nM367 15 v585 v600 v585 c2.667,10,9.667,15,21,15\\nc10,0,16.667,-5,20,-15 v-585 v-600 v-585 c-2.667,-10,-9.667,-15,-21,-15\\nc-10,0,-16.667,5,-20,15z M410 15 H367 v585 v600 v585 h43z\"}]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.65em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.02778em\"},\"children\":\"r\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.938em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.113em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mopen mtight\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"i\"}],[\"$\",\"span\",null,{\"className\":\"mclose mtight\",\"children\":\")\"}]]}]}]]}]}]}]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mbin\",\"children\":\"−\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"e\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"1.0448em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.4231em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"style\":{\"marginRight\":\"0.05724em\"},\"children\":\"j\"}]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.2198em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mopen mtight\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"i\"}],[\"$\",\"span\",null,{\"className\":\"mclose mtight\",\"children\":\")\"}]]}]}]]}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.413em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":[\"$\",\"span\",null,{\"className\":\"delimsizing mult\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"1.15em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.15em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3.8em\"}}],[\"$\",\"span\",null,{\"style\":{\"width\":\"0.556em\",\"height\":\"1.800em\"},\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":\"0.556em\",\"height\":\"1.800em\",\"viewBox\":\"0 0 556 1800\",\"children\":[\"$\",\"path\",null,{\"d\":\"M145 15 v585 v600 v585 c2.667,10,9.667,15,21,15\\nc10,0,16.667,-5,20,-15 v-585 v-600 v-585 c-2.667,-10,-9.667,-15,-21,-15\\nc-10,0,-16.667,5,-20,15z M188 15 H145 v585 v600 v585 h43z\\nM367 15 v585 v600 v585 c2.667,10,9.667,15,21,15\\nc10,0,16.667,-5,20,-15 v-585 v-600 v-585 c-2.667,-10,-9.667,-15,-21,-15\\nc-10,0,-16.667,5,-20,15z M410 15 H367 v585 v600 v585 h43z\"}]}]}]]}]}],\"$Lb0\"]}],\"$Lb1\"]}]}]}]]}],\"$Lb2\"]}]\n"])</script><script>self.__next_f.push([1,"95:[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}]\n96:[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}]\n97:[\"$\",\"span\",null,{}]\n98:[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}]\n99:[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"x\"}]\n9a:[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\"))\"}]\n9b:[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\".\"}]\n9c:[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[\"$\",\"span\",null,{\"className\":\"delimsizing size1\",\"children\":\")\"}]}]\n9d:[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}]\n9e:[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\"))\"}]\n9f:[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}]\na0:[\"$\",\"span\",null,{\"className\":\"mbin\",\"children\":\"+\"}]\na1:[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}]\n"])</script><script>self.__next_f.push([1,"a2:[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"1em\",\"verticalAlign\":\"-0.25em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.07378em\"},\"children\":\"ζ\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3361em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.0738em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord text mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"offset\"}]}]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"o\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.2806em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mathnormal mtight\",\"children\":\"t\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\".\"}]]}]\n"])</script><script>self.__next_f.push([1,"a3:[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.41em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.10903em\"},\"children\":\"M\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3361em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.109em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord text mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"bin\"}]}]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]}]]}]\na4:[\"$\",\"span\",null,{\"style\":{\"top\":\"-0.91em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord text\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"action_tokens\"}]}]}]]}]\na5:[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]\na6:[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"2.75em\"},\"children\":[\"$\",\"span\",null,{}]}]}]\n"])</script><script>self.__next_f.push([1,"a7:[\"$\",\"span\",null,{\"className\":\"col-align-l\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"3.25em\"},\"children\":[[\"$\",\"span\",null,{\"style\":{\"top\":\"-5.41em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"2\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mbin\",\"children\":\"⋅\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mord text\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"quantile\"}]}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"a\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mbin\",\"children\":\"−\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2222em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"1\"}]]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-3.91em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mord text\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"DCT\"}]}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"a\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.1514em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"0em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord text mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"norm\"}]}]}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.41em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"⌊\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.05556em\"},\"children\":\"γ\"}],[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.10903em\"},\"children\":\"M\"}],[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\"⌋\"}]]}]]}],[\"$\",\"span\",null,{\"style\":{\"top\":\"-0.91em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"3em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mrel\",\"children\":\"=\"}],[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.2778em\"}}],[\"$\",\"span\",null,{\"className\":\"mord text\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":\"BPE\"}]}],[\"$\",\"span\",null,{\"className\":\"mopen\",\"children\":\"(\"}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.10903em\"},\"children\":\"M\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3361em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.109em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord text mtight\",\"children\":\"$Lb3\"}]}]}]]}]}],\"$Lb4\"]}],\"$Lb5\"]}]}]]}],\"$Lb6\",\"$Lb7\",\"$Lb8\",\"$Lb9\"]}]]}]]}],\"$Lba\"]}],\"$Lbb\"]}]}]\n"])</script><script>self.__next_f.push([1,"a8:[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.0359em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"0\"}]}]]}]\na9:[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]\naa:[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]\nab:[\"$\",\"a\",null,{\"href\":\"https://www.pi.website/research/real_time_chunking\",\"children\":\"Real-time Chunking\"}]\nac:[\"$\",\"li\",null,{\"children\":[\"🟢 \",[\"$\",\"strong\",null,{\"children\":\"Residual VQ-VAE:\"}],\" Vector quantization is surprisingly fast. This is one of the improvements leveraged by \",[\"$\",\"a\",null,{\"href\":\"https://ai.stanford.edu/blog/minivla/\",\"children\":\"MiniVLA\"}],\" (Dec. 2024) to reach OpenVLA-level performance at 2.5× the speed.\"]}]\n"])</script><script>self.__next_f.push([1,"ad:[\"$\",\"li\",null,{\"children\":[\"🟢 \",[\"$\",\"strong\",null,{\"children\":\"Diffusion:\"}],\" While diffusion methods were once thought to be too slow for high-frequency control, \",[\"$\",\"span\",null,{\"className\":\"katex\",\"children\":[[\"$\",\"span\",null,{\"className\":\"katex-mathml\",\"children\":[\"$\",\"math\",null,{\"xmlns\":\"http://www.w3.org/1998/Math/MathML\",\"children\":[\"$\",\"semantics\",null,{\"children\":[[\"$\",\"mrow\",null,{\"children\":[\"$\",\"msub\",null,{\"children\":[[\"$\",\"mi\",null,{\"children\":\"π\"}],[\"$\",\"mn\",null,{\"children\":\"0\"}]]}]}],[\"$\",\"annotation\",null,{\"encoding\":\"application/x-tex\",\"children\":\"\\\\pi_0\"}]]}]}]}],[\"$\",\"span\",null,{\"className\":\"katex-html\",\"aria-hidden\":\"true\",\"children\":[\"$\",\"span\",null,{\"className\":\"base\",\"children\":[[\"$\",\"span\",null,{\"className\":\"strut\",\"style\":{\"height\":\"0.5806em\",\"verticalAlign\":\"-0.15em\"}}],[\"$\",\"span\",null,{\"className\":\"mord\",\"children\":[[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"style\":{\"marginRight\":\"0.03588em\"},\"children\":\"π\"}],[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.3011em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.55em\",\"marginLeft\":\"-0.0359em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"0\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]]}]]}]}]]}],\" reaches appreciable frequencies under continuous actions. Aggressive action chunking seems to play a role.\"]}]\n"])</script><script>self.__next_f.push([1,"ae:[\"$\",\"li\",null,{\"children\":[\"🟡 \",[\"$\",\"strong\",null,{\"children\":\"Quantile binning:\"}],\" OpenVLA can run acceptably with 4-bit precision, and we suspect that this is partially possible because this action quantization makes better use of the available number of action tokens. However, even in 4-bit precision the frequency is fairly slow, and we would expect the tradeoffs with respect to dexterity to be rather severe.\"]}]\naf:[\"$\",\"li\",null,{\"children\":[\"🔴 \",[\"$\",\"strong\",null,{\"children\":\"Naive binning:\"}],\" RT-2 is slow, mostly for reasons upstream of action tokenization, but it does play a role. While the action tokenization scheme is simple and therefore nominally fast, one might observe that failing to meaningfully compress actions at the token level implies some amount of unnecessary bloat and slowdown in action representation.\"]}]\n"])</script><script>self.__next_f.push([1,"b0:[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]\nb1:[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.65em\"},\"children\":[\"$\",\"span\",null,{}]}]}]\nb2:[\"$\",\"span\",null,{\"className\":\"msupsub\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist-t vlist-t2\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"-0.2486em\"},\"children\":[\"$\",\"span\",null,{\"style\":{\"top\":\"-2.0003em\",\"marginRight\":\"0.05em\"},\"children\":[[\"$\",\"span\",null,{\"className\":\"pstrut\",\"style\":{\"height\":\"2.7em\"}}],[\"$\",\"span\",null,{\"className\":\"sizing reset-size6 size3 mtight\",\"children\":[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"2\"}]}]]}]}],[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]]}],[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.6997em\"},\"children\":[\"$\",\"span\",null,{}]}]}]]}]}]\nb3:[\"$\",\"span\",null,{\"className\":\"mord mtight\",\"children\":\"bin\"}]\nb4:[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]\nb5:[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"0.15em\"},\"children\":[\"$\",\"span\",null,{}]}]}]\nb6:[\"$\",\"span\",null,{\"className\":\"mpunct\",\"children\":\",\"}]\nb7:[\"$\",\"span\",null,{\"className\":\"mspace\",\"style\":{\"marginRight\":\"0.1667em\"}}]\nb8:[\"$\",\"span\",null,{\"className\":\"mord mathnormal\",\"children\":\"ϕ\"}]\nb9:[\"$\",\"span\",null,{\"className\":\"mclose\",\"children\":\")\"}]\nba:[\"$\",\"span\",null,{\"className\":\"vlist-s\",\"children\":\"​\"}]\nbb:[\"$\",\"span\",null,{\"className\":\"vlist-r\",\"children\":[\"$\",\"span\",null,{\"className\":\"vlist\",\"style\":{\"height\":\"2.75em\"},\"children\":[\"$\",\"span\",null,{}]}]}]\n"])</script><script>self.__next_f.push([1,"9:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"bc:I[72551,[\"/staging/pulls/27/_next/static/chunks/e3f3620ea1ae9685.js\",\"/staging/pulls/27/_next/static/chunks/feb976563fece928.js\"],\"IconMark\"]\n7:null\nb:[[\"$\",\"title\",\"0\",{\"children\":\"Evaluating Vector Quantization for VLA Action Tokenization - VLA Foundations\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"RT-1 (2022), VQ-BeT (ICML 2024), MotionLM (2023)\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/staging/pulls/27/favicon.ico?favicon.0b3bf435.ico\",\"sizes\":\"256x256\",\"type\":\"image/x-icon\"}],[\"$\",\"$Lbc\",\"3\",{}]]\n"])</script></body></html>