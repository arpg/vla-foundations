1:"$Sreact.fragment"
2:I[69460,["/staging/pulls/46/_next/static/chunks/3421e88d40c9134c.js","/staging/pulls/46/_next/static/chunks/fbf372f7eb8336a2.js"],"default"]
3:I[24820,["/staging/pulls/46/_next/static/chunks/3421e88d40c9134c.js","/staging/pulls/46/_next/static/chunks/fbf372f7eb8336a2.js"],"default"]
5:I[39795,["/staging/pulls/46/_next/static/chunks/3421e88d40c9134c.js","/staging/pulls/46/_next/static/chunks/fbf372f7eb8336a2.js"],"OutletBoundary"]
6:"$Sreact.suspense"
8:I[39795,["/staging/pulls/46/_next/static/chunks/3421e88d40c9134c.js","/staging/pulls/46/_next/static/chunks/fbf372f7eb8336a2.js"],"ViewportBoundary"]
a:I[39795,["/staging/pulls/46/_next/static/chunks/3421e88d40c9134c.js","/staging/pulls/46/_next/static/chunks/fbf372f7eb8336a2.js"],"MetadataBoundary"]
c:I[8528,[],"default"]
:HL["/staging/pulls/46/_next/static/chunks/7934be6db471e3e4.css","style"]
:HL["/staging/pulls/46/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/staging/pulls/46/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
0:{"P":null,"b":"wKxnG9z0w-VNgeYtL8ZDL","c":["","textbook","architectures",""],"q":"","i":false,"f":[[["",{"children":["textbook",{"children":[["slug","architectures","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/staging/pulls/46/_next/static/chunks/7934be6db471e3e4.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased","children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":[null,["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["$","$1","c",{"children":["$L4",[["$","script","script-0",{"src":"/staging/pulls/46/_next/static/chunks/c1bf14c0d1162836.js","async":true,"nonce":"$undefined"}]],["$","$L5",null,{"children":["$","$6",null,{"name":"Next.MetadataOutlet","children":"$@7"}]}]]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],["$","$1","h",{"children":[null,["$","$L8",null,{"children":"$L9"}],["$","div",null,{"hidden":true,"children":["$","$La",null,{"children":["$","$6",null,{"name":"Next.Metadata","children":"$Lb"}]}]}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],false]],"m":"$undefined","G":["$c",[]],"S":true}
d:I[47737,["/staging/pulls/46/_next/static/chunks/c1bf14c0d1162836.js"],"Sidebar"]
4:["$","div",null,{"className":"flex min-h-screen","children":[["$","$Ld",null,{"chapters":[{"title":"Foundations: Introduction to the VLA Stack","chapter":0,"description":"Foundational concepts for Vision-Language-Action systems in robotics","slug":"foundations"},{"title":"Architectures: VLA Model Designs","chapter":1,"description":"Model architectures, multi-modal encoders, and policy networks for robotics","slug":"architectures"},{"title":"Data: Dataset Construction and Curation","chapter":2,"description":"Data collection, annotation strategies, and quality assurance for robotics","slug":"data"},{"title":"Training: Optimization and Learning Methods","chapter":3,"description":"Training strategies, fine-tuning, and optimization for robotic control","slug":"training"},{"title":"Evaluation: Metrics and Benchmarking","chapter":4,"description":"Success metrics, safety validation, and benchmarking protocols for VLA systems","slug":"evaluation"},{"title":"Deployment: Production Systems and Scaling","chapter":5,"description":"From semantic supervision to safety-critical validation for autonomous fleets","slug":"deployment"},{"title":"Applications: Real-World Use Cases","chapter":6,"description":"Case studies and practical applications of VLA systems across domains","slug":"applications"},{"title":"Future Directions: Open Problems and Research Frontiers","chapter":7,"description":"Emerging trends, unsolved challenges, and the path forward for VLA research","slug":"future"}]}],["$","main",null,{"className":"flex-1 flex","children":[["$","article",null,{"className":"flex-1 max-w-4xl mx-auto px-8 py-12","children":["$","div",null,{"className":"prose prose-lg prose-slate max-w-none","children":"$Le"}]}],["$","aside",null,{"className":"hidden xl:block w-64 border-l border-gray-200 bg-gray-50 p-6 overflow-y-auto h-screen sticky top-0","children":[["$","div",null,{"className":"text-xs font-semibold text-gray-500 uppercase tracking-wide mb-3","children":"On This Page"}],["$","div",null,{"className":"text-sm text-gray-600","children":["$","p",null,{"className":"text-xs italic","children":"Table of contents"}]}]]}]]}]]}]
e:[["$","h1",null,{"children":"Chapter 1: Architectures"}],"\n",["$","h2",null,{"children":"Core Questions"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"How do we tokenize continuous physical space?"}],"\n",["$","li",null,{"children":"What makes a good latent space for robotic control?"}],"\n",["$","li",null,{"children":"How do we align vision, language, and action modalities?"}],"\n"]}],"\n",["$","h2",null,{"children":"Topics"}],"\n",["$","h3",null,{"children":"1.1 Scene Encoders"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"Vision transformers for spatial understanding"}],"\n",["$","li",null,{"children":"Depth integration and 3D representations"}],"\n",["$","li",null,{"children":"Temporal encoding for dynamic scenes"}],"\n"]}],"\n",["$","h3",null,{"children":"1.2 Multi-Modal Alignment"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"Contrastive learning for vision-language"}],"\n",["$","li",null,{"children":"Action space grounding"}],"\n",["$","li",null,{"children":"The embedding geometry problem"}],"\n"]}],"\n",["$","h3",null,{"children":"1.3 Tokenization Strategies"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"Discrete vs. continuous representations"}],"\n",["$","li",null,{"children":"Spatial vs. semantic tokens"}],"\n",["$","li",null,{"children":"Compression-fidelity trade-offs"}],"\n"]}]]
9:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
f:I[27654,["/staging/pulls/46/_next/static/chunks/3421e88d40c9134c.js","/staging/pulls/46/_next/static/chunks/fbf372f7eb8336a2.js"],"IconMark"]
7:null
b:[["$","title","0",{"children":"Architectures: VLA Model Designs - VLA Stack"}],["$","meta","1",{"name":"description","content":"Model architectures, multi-modal encoders, and policy networks for robotics"}],["$","link","2",{"rel":"icon","href":"/staging/pulls/46/favicon.ico?favicon.0b3bf435.ico","sizes":"256x256","type":"image/x-icon"}],["$","$Lf","3",{}]]
