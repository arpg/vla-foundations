1:"$Sreact.fragment"
2:I[47737,["/staging/pulls/48/_next/static/chunks/8d071409e29bfe4f.js"],"Sidebar"]
7:I[39795,["/staging/pulls/48/_next/static/chunks/3421e88d40c9134c.js","/staging/pulls/48/_next/static/chunks/fbf372f7eb8336a2.js"],"OutletBoundary"]
8:"$Sreact.suspense"
0:{"buildId":"k6eKTY5DpmAUKfPV6z--g","rsc":["$","$1","c",{"children":[["$","div",null,{"className":"flex min-h-screen","children":[["$","$L2",null,{"chapters":[{"title":"Foundations: Introduction to the VLA Stack","chapter":0,"description":"Foundational concepts for Vision-Language-Action systems in robotics","slug":"foundations"},{"title":"Architectures: VLA Model Designs","chapter":1,"description":"Model architectures, multi-modal encoders, and policy networks for robotics","slug":"architectures"},{"title":"Data: Dataset Construction and Curation","chapter":2,"description":"Data collection, annotation strategies, and quality assurance for robotics","slug":"data"},{"title":"Training: Optimization and Learning Methods","chapter":3,"description":"Training strategies, fine-tuning, and optimization for robotic control","slug":"training"},{"title":"Evaluation: Metrics and Benchmarking","chapter":4,"description":"Success metrics, safety validation, and benchmarking protocols for VLA systems","slug":"evaluation"},{"title":"Deployment: Production Systems and Scaling","chapter":5,"description":"From semantic supervision to safety-critical validation for autonomous fleets","slug":"deployment"},{"title":"Applications: Real-World Use Cases","chapter":6,"description":"Case studies and practical applications of VLA systems across domains","slug":"applications"},{"title":"Future Directions: Open Problems and Research Frontiers","chapter":7,"description":"Emerging trends, unsolved challenges, and the path forward for VLA research","slug":"future"}]}],["$","main",null,{"className":"flex-1 flex","children":[["$","article",null,{"className":"flex-1 max-w-4xl mx-auto px-8 py-12","children":["$","div",null,{"className":"prose prose-lg prose-slate max-w-none","children":[["$","h1",null,{"children":"Chapter 0: Foundations"}],"\n",["$","p",null,{"children":"The Vision-Language-Action (VLA) stack represents the fundamental architecture for building intelligent robotic systems that can perceive, reason, and act in the physical world."}],"\n",["$","h2",null,{"children":"The Core Problem"}],"\n",["$","p",null,{"children":"Given:"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"Scene encoding (visual perception)"}],"\n",["$","li",null,{"children":"Natural language instruction (task specification)"}],"\n"]}],"\n",["$","p",null,{"children":"Find:"}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"Action sequence (robot control)"}],"\n"]}],"\n",["$","h2",null,{"children":"Textbook Structure"}],"\n",["$","p",null,{"children":"This living textbook covers the complete VLA pipeline across 8 chapters:"}],"\n",["$","ol",null,{"start":"0","children":["\n",["$","li",null,{"children":[["$","strong",null,{"children":"Foundations"}]," - Core concepts and problem formulation"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Architectures"}]," - Model designs and network topologies"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Data"}]," - Dataset construction and curation strategies"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Training"}]," - Optimization and fine-tuning methods"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Evaluation"}]," - Metrics and benchmarking protocols"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Deployment"}]," - Production systems and scaling"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Applications"}]," - Real-world use cases and case studies"]}],"\n",["$","li",null,{"children":[["$","strong",null,{"children":"Future Directions"}]," - Open problems and research frontiers"]}],"\n"]}],"\n",["$","p",null,{"children":"Each chapter builds on rigorous validation principles and real-world deployment constraints."}]]}]}],["$","aside",null,{"className":"hidden xl:block w-64 border-l border-slate-300 bg-gradient-to-b from-slate-50 to-slate-100 p-6 overflow-y-auto h-screen sticky top-0","children":[["$","div",null,{"className":"text-xs font-semibold text-slate-500 uppercase tracking-wider mb-3 flex items-center gap-2","children":["$L3","On This Page"]}],"$L4"]}]]}]]}],["$L5"],"$L6"]}],"loading":null,"isPartial":false}
3:["$","span",null,{"className":"w-1 h-4 bg-teal-500 rounded-full"}]
4:["$","div",null,{"className":"text-sm text-slate-600","children":["$","p",null,{"className":"text-xs italic text-slate-500","children":"Table of contents"}]}]
5:["$","script","script-0",{"src":"/staging/pulls/48/_next/static/chunks/8d071409e29bfe4f.js","async":true}]
6:["$","$L7",null,{"children":["$","$8",null,{"name":"Next.MetadataOutlet","children":"$@9"}]}]
9:null
